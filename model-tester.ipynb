{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c98c2432",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.ocr_pdf import ocr_pdf_async"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62917ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "roll = \"g8\"\n",
    "sub = \"devops\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0806dd57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCR is running in background...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:modules.ocr_pdf:Initializing EasyOCR reader...\n",
      "WARNING:easyocr.easyocr:Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "OCR pages: 100%|██████████| 35/35 [04:06<00:00,  7.05s/it]\n"
     ]
    }
   ],
   "source": [
    "future = ocr_pdf_async(\n",
    "    f\"test-material/{roll}/{sub}.pdf\",\n",
    "    method=\"easyocr\",\n",
    "    pages=\"all\",\n",
    "    lang=\"en\",\n",
    "    gpu=True\n",
    ")\n",
    "print(\"OCR is running in background...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d20d804b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = future.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c90c256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'--- PAGE 1 ---\\nINSTITUTE OF AERONAUTICAL ENGINEERING (Autonomous) 1 Dundigal 500 043, Hyderabad, Telangana\\nExaminations Control Office\\nExamination B TECH  VI SEMESTER END EXAMINATIONS REGULAR JUNE 2025 REG UG20\\nMonth & Year 1-Jun\\nDate 20/06/2025\\nCourse Name DEVOPS\\nCourse Code ACSC42\\nE-Code 6775\\nInstructions to Evaluators Evaluators should spend at least 3-5 minutes on one answer booklet during the evaluation. Evaluators should cross check that marks are allotted for all the attempted questions. The marks   should be  assigned  fairly according to the mark   distribution specified in the scheme of evaluation. For questions that were attempted incorrectly, evaluators are required to award zero marks. The evaluator must give proper justification in case of any mistakes identified in the marks provided.\\n1\\n\\n--- PAGE 2 ---\\nSTART WRITING FROM HERE\\nQNo.\\n1.0 Brnching   qnd Mzig ing i0 Sil\\nQil is an open? Souyce disHi buted Veysio) conkol plaHfxn Ihq 4 Ovovidu Vori fus SqYui ( (es, 9il allows, Gs fo crcate Mullipk Qumber brnches fct fbe same repostloyy  xeposi {oyy 1S 0 cUdle bafe gien Pyqjeck. Theye Coa bc 0uny bxanche {o 0 Ye pos\\' bovy ~htch Wi |l be maltaneo bs diPexent teans; Suppose Ref WJ conf ale Product ehich is 60 Pkduchzon And ine Compoo5 Donf adal mulfiple idepnolkat Realuye Iol py ducf_ Heve the (ompony Lil cxa te One 06 bxonch Rr ea ck Jealuve each Ratuye Rs idpea &le: Qod 8oes + rel5 60 0 Ipev nes Jaluye , Heee each branch i5 dested aad build Thea Ih 060 (lo (allhc ) Ye rpostl (torh) will havl Ihe au fhaxi /y mkys< thest bxonchu ucH fLe Qxudu ctio ^ boonch. Aadl ~h ayfhov is vexponi 61 & 6 8, occepling: fhe pu (r YesGesd ~ox ku blonch aad on/5 Inea i9 i sgk to delek_Ih JacAuvt bxoncL 1/34\\n\\n--- PAGE 3 ---\\nQ.No.\\n(ei) katuic  kol Reoluve (B2) 6\\' J gronhiqs\\nPyoduc Idion &ranch\\nnegin) 83 #\".ti;\\n6761c6,5 0, katuu\" (Bz)\\nNeyjin) B2 Jil Plec\\nRs\\n~3f\" erede tlie+ edlky bgb, Ihu producHia pranch win hav # (C4) Raluyu % Gvonches . Magoging Eoalicks Eonlhcb SdMC tine Occuv ah You aye Qahins (mexslo5 thc branches: Th bet pracktes fv mcncqing confit iq Git is QOjuye fhe Hles QYC Pxvpexly imported, Ada all xelakd Madule CY € Quk 6 Gtf pyopexly 40 CCue Co  AAticf 6c4 9uqtdida wii Jhocj fhl 0Gxb 9 Co de fhat QYc Jeacliog Y meySe Con Aecf CE Jhoulal Ytadlue fhe co oac E , Oaly Tra #u Gxonthe C^ be Merfed Wit Pxduc Fon ByoacL\\n2/34\\n\\n--- PAGE 4 ---\\nQ.No\\n1,6\\nStrugg\\' Alioq Lith maialaining Consisteacy i0 inkasksutf_ uye confguyatioc ^f a(cvoss mulliple e vironmeats\\nJasonsisloncy in maia 1-lataing jofsasfsaclux Confgurafions acc boss Mu  ltiple entyonmerd Could (eat fo icfuesr   lrke Syflen cocsn (ve Acteasabiltby Arbpl problemn$ , Protabi li  1 {scu& pey-lraankee \"dfues and Bad (Jt( expecienc 2 {c. Yaglerkaling Jakasbucfur CS 6de \" ( Iac) will Jolve Xhif LAf0n in consislo(y challeagc 2 Ouy iSsue= is ralled on multiple eau vonmeat toge Jafcuhuc luvr Q code esilf help Mai 4a, fne condukcat5 iQ ioPoufuctuve Coo Rgaxtionn OccYan te Mu(tiple eaviynme{ Chic chvecth Yesdue Pwbleru uif dlxntiny Qesponge Hine Mullple Qaui Yonm(9f jJJ06 scalcbi |iky {SJte ) aad pcxbyane ieue T6 imdeme[ Lelastsuthuvc O) Codkty Iku Nevelopes fean JhackI have Joodl kacslelse obou- huv code Hat con bz Modulieol , reuGabfe e-#tict 4 fo Ahe) Jhold Solio psiaciplu Aol ioplewwf Prxlsimaate +eda 56\" lxke CG chin} Qacf fnpltac+ tUey e78er(m = fcaut Jike\\n3/34\\n\\n--- PAGE 5 ---\\nQNo.\\nRe #ekh an xeRetch _ hi Hr a ce mnod {Jq 67 Maq7 pyedlucb ma ke csaw feel like fh dala i Loaded icfaq toneocsly - Bu ro yalih the all cafa #al Cllv coufl Jer ir prc Roaded eho ao applic icshia 1J opentd , and thu dala V Ytfruhtd Gnd stxed ~heo UJfv Qpra} jhe_prtriclen paje _ 7his give 00 illetfon that fhe dafa 18 Woodtol ioctaneoculy (Jio9 Fht te choisil Thu probless 0t io ) consjsHer) 10 in Rastuachuk cn figuralion accon Mulfipk envsameah ccld be slueal 44105 fre (Lalautvuckun 0J Coca (Joc) tchaiquer\\n4/34\\n\\n--- PAGE 6 ---\\nQNo.\\n20\\nSubVexslea: CSVN) aod 6;4\\nhey   archilecfuxal difexences 8 Subversio^ (SUN} System IS Oxn? kve Pile based Szfen _ Storu fhy each veysfon @X 4 Ilaley , Imi ted dline Conhi . lacks abilties like con fticf resolufion Oad rollbacks; Git is aq opea Souvce Vevsiun Contsol SoffJaye_ Back Version caa be sboved Q Q N(c Byanch Ualimiled cflline Ye \\'Paxkzz Confsel Hove Secicl abilikes ku like conlficf reSolution dnq Arstaaf Yollbactr\\ni) Jmpocl 0n Aeaos\\nUsing Subvexsion (SVN Gv 6i9 wil greaE ly impacf #e cal) Aeams Ck fhese tools Psy Veysro^ Co atso( 0a c collabxolion = 0) Uhile Usir) SUN SVN is pximilive\\n5/34\\n\\n--- PAGE 7 ---\\nQ No;\\nJle bosecl Vlrsion   confel Syslem. Usexz 0Y kac Face Q c(e85 Oy Oltodllock m0) iSfues _ chile #ryia9 Occess pctitelal lkcoa SvN is a ceatevlzedl Syten) chick could b2 VaqaroLlc f %e aflc kex; Out Mafacdl) propoy @ daly Coula be Cowcokdl 0t Foohecl ,\\nb,) _ thile uSing Gil 9il Is a dislbuka Syutm/ So Mil Ovaly ho oc hoxity fwont OY {(Vafe cCces ) 76 Qafeclar person m teao 614 if highhh Jecuve and QeecQ Ayopey Gukhtk cafia^\\nc4knce consalevo9 fne cdllaburottoa beftareo #l tam mlmbeyj ) Wirs 9i+ will Icp Yom and fimplifies fhu corplel cl chatins @nq (ade ~oocti)\\n6/34\\n\\n--- PAGE 8 ---\\nQNo:\\n2,6 Bug  hualig9 od sQuesling chaqge Cansidering) Fhe CCJ thaf 0 cctical bvs ~0 Owhtd t MCin - byand) in tn lalet cuma\\' { aJJUMn; matn _ branch O^ 0 Pxoduthon byanch 7he Rixst Rnq 49 c cjkr KaosJ.a5 Ihu bu9 i0 fhe Ovudackion 9 ~il ~6/l buck M AY ducfiv f6 H px(viall< (onnit iS (trtain Hhot Ahe bug avds intclurecl iq Th Jatesf   (omm\\'+ Qil Simplo Fit fk Tqeb tak, Jik Ocfivit5 Moa ( 1ro9 Ocal choa5es moifvin 9: AVr y(verlio5 fh chons back Tn frcviows< 00mmit t Qedy c ckun ~il (onfimocs Seyve Thu Oylviou) VCupa AUs + 6Ci acx tk bcsle fk mudcle tha+ C aulol mnaJo = Bu; Tbb Ve0 Altol Aaol Vun the Acosh t6 be cyaa Ia Certa  n tx bw) Klo bren YeAolvtol Cves f4a5 Qst Qoykj eapected , Nenk Step \"6 dlamagl Contsel maju _ (uy M hese could Cquje kus e monc/a? olanag Qs thxush Yhe Jycfr 89\\' anok\\n7/34\\n\\n--- PAGE 9 ---\\nQNo\\nTyz h Tollback th2 daa5e madc ln clalbase Ls The (ug LJhe q &u QYe PG lly (extor fh Wve CveaV 0q5 Ifjae ~il fk Qvodlu cf \\'pyjh ncin -Dvnch ,\\n#is @bs Vev)   eoy tack change h eac) (ommit. 6i} majatan 0 Ycco rd c each cuuld honj? ( Fhak pexJo   hcus Mq d chrch Fvgkc^ Casy Jarale &d Y(Ve + # dhang:\\n8/34\\n\\n--- PAGE 10 ---\\nQNo.\\n.6 \\'key componea b d _ chi-leclure c Docker\\nW Caa coasides dockrr Q1 Q tsl #hat Staplfies f poxlabi= 1it5 isfues . (Jhile dlevelopin) Pxoject CJL uilf 4J€ m0n) packase Ono  }inallh butld # Final Code; Thq (odle is nedeel be Yuon/0^ voxious_ devices ard cli ffestaf Ontra fin9 Jyhta_ Tf U 0 lficf t Ve Conkigure fhu Prejec/ Rx each devu e Hkyc iS choc Ooc kp (Onu in , dec   ing dockw UC Cao (veafe on Cockec Conla n_ shich hac Gn drki GaG)\" Fha A Can 62 cauly Ce dl 0^ cilfeo mf evtces ~ifh ouf 0ny add: fioqdl Con Prg ura tion\\nOochev Igle\\n(Docke, 2ag ine {S a JG - Pfacve ope licahbn thaf Cqo be dkyunbaded i 6 S6uv Jzfen Lhich Qxvide CLI conncnd Cin c Jatevface) Coakcf 1 (aocse fke dockey 0/ qo0/ Turnputev .\\n9/34\\n\\n--- PAGE 11 ---\\nQNo.\\nDoche_Hlub\\nDockev hub fs 0 beb   dalbr cshxi< pu Jbu _ Sout docke ~lQosttorig 2hich Coafa (ae Con fain exa and Jnagus\\nCockings Continev N q box_,uhich caq have Qlockrr inagu toxedl del_iai4._ Y are  cied to Yuq / maqSe [cakcl ImGJe, Ooche Gnages Oockes inGgu ave Biaa/y Pck Cylatrd 59 Xockxs ensit Muk 0ut o6f ohle Pxjec/ enc d ed i0 /4\\nNehyayk and Vslu mu\\n~Jhe tern pehsoak Anc( Volum Cued ja th decku 7 4ve aetyjacky jmasu called Voluny D hich Ci ) fsvcal G7 cLockev_hub\\n10/34\\n\\n--- PAGE 12 ---\\nQNo:\\n3.b\\n(ligroling Aom gonolilbic   ompliclbo Qxchilectyre\\nMicYo  seyvice\\n(onolilhic oppllta (ion is Qa Qpplica 6roa YhoF hos_6oly sigle blok Iakevac flos Hu Cet Mad @ dalbay . f+ Jodl hdve backraal JCVv( api\\'j acceclala) rf direcfl) pev lrms caltulaltu ^ and opeafea dafabye ead am MiCvo Sewite Gychitecfure _ Ihre Moy Sewic e bloc & anal each seyvi(c blac € wil ( Qevbto ol5 04 € Smple task . So Yaovck, t8 mlgval Maslifhi < aPplcafibo ink t6 0 Mtcyo scyvice architecfuve app ication, cing dkkev Coataing Jhe Rilossi25 Step t aw be xone, V) wvilin) (Iicro se Yvi ( 6s 2,0B   maajena/   wios 0n ORn  3/ Te Ho9 microseyvites 4/ Convaking (Ticvo Jeyviten 70 Sos; @ 5, Maoogin dockxv Gafoben , Yun #h Crtattel An49es 6 , Oepl.5in}\\n11/34\\n\\n--- PAGE 13 ---\\nQNo:\\n(oslihhic Ioplicolroa\\ntaSer\\ndahBar\\n(dlafabase)\\nmicTo Sexuic\\nmi(yoseyvite\\nmicrserJite\\nImggeL\\nIngr2\\nIncs3\\nOocher Conlinw\\n12/34\\n\\n--- PAGE 14 ---\\nQNo.\\nta. Mauol_tesl plag lor 0 Complx 4eb Applicotion\\nxek WS coniclev 0 complex Ejeb opplicalioa , ko Tvck 0 Fuliskck ~l cnelicaliog ted Qrg}ed monaSema } ho Yole bared Occ e5 TesF_plaq Meatiky fhle Cuer (xu 2 . 9deakify the ac(en @ 0 CocG USfly tpe 3. Qrqave Tet CC chaxf Gad tocluole_# abve G Cces & Godl Lail CQUU and Poss cojes 4 Jadluce edze cQies\\nNos Qef u6 jee Tt WJe cQe Ju maalal Aeoling 7h0u 0e fotal_c 5 _tye CNJ ey / {3Usex  admis `  StQu-oclnia ) O6g-mancg ey , Oyg WJey h #heJk are Mhet _ acrej Coealc_Ota Cyecdk 01 a(c WJi% aaq9e_Qrj ada ujin 4am5e Wt \"JJ py T F T F F Odoiin T F F F F JuQi adlmind T T T 7 7 T 6r5 - mqnfe F T T 049 F F F F WL F 13/34\\n\\n--- PAGE 15 ---\\nQ No\\nDased 00 fh foblc above , UC (Q^ curite Test tdsle like\\nTestoucSc SceaagYco UstvTye enptcte 1 Crcalc_0v9 Usc\\' 2. Cak 0x9 admiq 3 Ctlakc 0v Mgqoge,\\ndus 8 Eall\\nt F\\nP\\nManvallyy Opra fhu scke Gndl Jtg\"n Q difkevcat rulu and Ucdtdah fhetof ~ou tolle 65_Bcdl m19 bvf\\'\\n14/34\\n\\n--- PAGE 16 ---\\nQNo\\n+6\\nOrpvrative tulplan dor 0ty feafure\\ndo develop 0 ComPvehcasiv fesl_plan t6 easaye Full covcwse newj fealure in an opplicokoa, Afis mndalory iadude edge cases aad pokeafial Renlurc Pobh Mate Jhuyc then @real a1( bug\\' cd 24 0 ytad be Qxduted , Fidlls ~c shyld Ytd fv Yeuiyeaeaf FR prajecls Nkuj featuv Unclextaad 21 FuacHionaliky- ft help Jiool edSe cqst ~hilc ~eting Pesforms Uaif tesliay ialgrclloa telia9 / Qc fuqa feokio9 Loitl # x (0sy iacludecl cilk # eds CQJB Ajo CUe\\' Twp - Yocna Od/ (el(zaIka m 4p QPpyache Male Jhtan Mhete Ovcnu 0n5 bw)\\' ond uqeme fol bchaviouv 0}te Jeofuyt . Moki^9 thwve th Rea luvs mee/f Ysuiyc(ah Onq Cayl , cui 64 01 iour 15 OKy MGl9 Dyioytty fo Xevclep (onprchjiu e feal_plaal fo (O/uv tx Eu coVCrcSe c_ # nlv Jeafurea 10 Q 0 Gpplitalion\\n15/34\\n\\n--- PAGE 17 ---\\nQ No;\\n6.0\\nAmazo^ Elasttc 6rpcti /9 ia Jewvile Arovded b5 Amao^ LJeb Jwite ( Aws) , Gyhich Srli pyovide 0\\' Virtuol 6Machine Oa Ag $ cloud Th Osc tvu al Ec Swie Qik YCJe Vucd tasfance , 00 - demurdl Iotance Spot inslanck . 0+ i$ iripo ) Yloa k 16 chte Mhu Mosk_ stable Qactagc Modef haed 6^ H Cje) € 42 Oo cue SJil be sein? Ca em \\'Ichol lcvge Jumben 0^ 0 UV Mloalh billn; 2C2 Resevucd mhb Ioufaa €c Ook scdloble 0a4  JcifaSlc@ Mii_eyucv chec_Bael Ost ewpeckd On_olemaacl Sadtn (e Hlevt 7F ic_ScalaSk baed 04 #z ta-lfic th Mtovh ancl bind ials Jaccajes Spot -on Jaataa € 4ese Juv Jevvcr Ir alyeads J cslecl eifl Xop halcvavc , Yhv 1S efficccat 70 5 Gpp em Occf , Coafincou #aflic\\n16/34\\n\\n--- PAGE 18 ---\\nQNo.\\n6b,\\nAdvaabge = 4_cleolyin;\\nDockes (a haberrz\\nOock (oataine= Oyc ealh/h Qurta blk , no Oeed iolall pacEaSe al_&_t Jefup\\nGash acces\\nW tt\\nJtoplxi Hz.\\nSas RAplttaktum packoging Stcpk deqasccy nqaqSenaf 7 Cv) It 8ckez i0GSc ab havs cli Qeecleo Qcckase\\n&ay] clplo) QccY0) dilesa f QV (Knmel, Aeke Ljrcldus / Equh Gad Mlacof\\n17/34\\n\\n--- PAGE 19 ---\\nQNo:\\n18/34\\n\\n--- PAGE 20 ---\\nQNo.\\n19/34\\n\\n--- PAGE 21 ---\\nQNo:\\n20/34\\n\\n--- PAGE 22 ---\\nQNo.\\n21/34\\n\\n--- PAGE 23 ---\\nQ No:\\n22/34\\n\\n--- PAGE 24 ---\\nFc0 Li0\\nQNo\\n23/34\\n\\n--- PAGE 25 ---\\nQNo\\n24/34\\n\\n--- PAGE 26 ---\\nQNo.\\n25/34\\nVonl\\n\\n--- PAGE 27 ---\\nQNo:\\n26/34\\n\\n--- PAGE 28 ---\\nQNo.\\n27/34\\nJi\\n\\n--- PAGE 29 ---\\nQNo\\n28/34\\n\\n--- PAGE 30 ---\\nQNo.\\n29/34\\n\\n--- PAGE 31 ---\\nQNo.\\n30/34\\n\\n--- PAGE 32 ---\\nQNo:\\n31/34\\n1\\n\\n--- PAGE 33 ---\\nQNo\\n32/34\\n\\n--- PAGE 34 ---\\nQNo_\\n33/34\\n\\'844\\n\\n--- PAGE 35 ---\\nROUGH WORK\\nContent written here will not be considered for valuation\\n34/34'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[\"combined_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5ef546b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Q.No\\n1,6\\nStrugg\\' Alioq Lith maialaining Consisteacy i0 inkasksutf_ uye confguyatioc ^f a(cvoss mulliple e vironmeats\\nJasonsisloncy in maia 1-lataing jofsasfsaclux Confgurafions acc boss Mu  ltiple entyonmerd Could (eat fo icfuesr   lrke Syflen cocsn (ve Acteasabiltby Arbpl problemn$ , Protabi li  1 {scu& pey-lraankee \"dfues and Bad (Jt( expecienc 2 {c. Yaglerkaling Jakasbucfur CS 6de \" ( Iac) will Jolve Xhif LAf0n in consislo(y challeagc 2 Ouy iSsue= is ralled on multiple eau vonmeat toge Jafcuhuc luvr Q code esilf help Mai 4a, fne condukcat5 iQ ioPoufuctuve Coo Rgaxtionn OccYan te Mu(tiple eaviynme{ Chic chvecth Yesdue Pwbleru uif dlxntiny Qesponge Hine Mullple Qaui Yonm(9f jJJ06 scalcbi |iky {SJte ) aad pcxbyane ieue T6 imdeme[ Lelastsuthuvc O) Codkty Iku Nevelopes fean JhackI have Joodl kacslelse obou- huv code Hat con bz Modulieol , reuGabfe e-#tict 4 fo Ahe) Jhold Solio psiaciplu Aol ioplewwf Prxlsimaate +eda 56\" lxke CG chin} Qacf fnpltac+ tUey e78er(m = fcaut Jike\\n3/34'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[\"pages\"][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87d0bd34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START WRITING FROM HERE\n",
      "QNo.\n",
      "1.0 Brnching   qnd Mzig ing i0 Sil\n",
      "Qil is an open? Souyce disHi buted Veysio) conkol plaHfxn Ihq 4 Ovovidu Vori fus SqYui ( (es, 9il allows, Gs fo crcate Mullipk Qumber brnches fct fbe same repostloyy  xeposi {oyy 1S 0 cUdle bafe gien Pyqjeck. Theye Coa bc 0uny bxanche {o 0 Ye pos' bovy ~htch Wi |l be maltaneo bs diPexent teans; Suppose Ref WJ conf ale Product ehich is 60 Pkduchzon And ine Compoo5 Donf adal mulfiple idepnolkat Realuye Iol py ducf_ Heve the (ompony Lil cxa te One 06 bxonch Rr ea ck Jealuve each Ratuye Rs idpea &le: Qod 8oes + rel5 60 0 Ipev nes Jaluye , Heee each branch i5 dested aad build Thea Ih 060 (lo (allhc ) Ye rpostl (torh) will havl Ihe au fhaxi /y mkys< thest bxonchu ucH fLe Qxudu ctio ^ boonch. Aadl ~h ayfhov is vexponi 61 & 6 8, occepling: fhe pu (r YesGesd ~ox ku blonch aad on/5 Inea i9 i sgk to delek_Ih JacAuvt bxoncL 1/34\n"
     ]
    }
   ],
   "source": [
    "print(output[\"pages\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ceb49a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- PAGE 1 ---\n",
      "INSTITUTE OF AERONAUTICAL ENGINEERING (Autonomous) 1 Dundigal 500 043, Hyderabad, Telangana\n",
      "Examinations Control Office\n",
      "Examination B TECH  VI SEMESTER END EXAMINATIONS REGULAR JUNE 2025 REG UG20\n",
      "Month & Year 1-Jun\n",
      "Date 20/06/2025\n",
      "Course Name DEVOPS\n",
      "Course Code ACSC42\n",
      "E-Code 6775\n",
      "Instructions to Evaluators Evaluators should spend at least 3-5 minutes on one answer booklet during the evaluation. Evaluators should cross check that marks are allotted for all the attempted questions. The marks   should be  assigned  fairly according to the mark   distribution specified in the scheme of evaluation. For questions that were attempted incorrectly, evaluators are required to award zero marks. The evaluator must give proper justification in case of any mistakes identified in the marks provided.\n",
      "1\n",
      "\n",
      "--- PAGE 2 ---\n",
      "START WRITING FROM HERE\n",
      "QNo.\n",
      "1.0 Brnching   qnd Mzig ing i0 Sil\n",
      "Qil is an open? Souyce disHi buted Veysio) conkol plaHfxn Ihq 4 Ovovidu Vori fus SqYui ( (es, 9il allows, Gs fo crcate Mullipk Qumber brnches fct fbe same repostloyy  xeposi {oyy 1S 0 cUdle bafe gien Pyqjeck. Theye Coa bc 0uny bxanche {o 0 Ye pos' bovy ~htch Wi |l be maltaneo bs diPexent teans; Suppose Ref WJ conf ale Product ehich is 60 Pkduchzon And ine Compoo5 Donf adal mulfiple idepnolkat Realuye Iol py ducf_ Heve the (ompony Lil cxa te One 06 bxonch Rr ea ck Jealuve each Ratuye Rs idpea &le: Qod 8oes + rel5 60 0 Ipev nes Jaluye , Heee each branch i5 dested aad build Thea Ih 060 (lo (allhc ) Ye rpostl (torh) will havl Ihe au fhaxi /y mkys< thest bxonchu ucH fLe Qxudu ctio ^ boonch. Aadl ~h ayfhov is vexponi 61 & 6 8, occepling: fhe pu (r YesGesd ~ox ku blonch aad on/5 Inea i9 i sgk to delek_Ih JacAuvt bxoncL 1/34\n",
      "\n",
      "--- PAGE 3 ---\n",
      "Q.No.\n",
      "(ei) katuic  kol Reoluve (B2) 6' J gronhiqs\n",
      "Pyoduc Idion &ranch\n",
      "negin) 83 #\".ti;\n",
      "6761c6,5 0, katuu\" (Bz)\n",
      "Neyjin) B2 Jil Plec\n",
      "Rs\n",
      "~3f\" erede tlie+ edlky bgb, Ihu producHia pranch win hav # (C4) Raluyu % Gvonches . Magoging Eoalicks Eonlhcb SdMC tine Occuv ah You aye Qahins (mexslo5 thc branches: Th bet pracktes fv mcncqing confit iq Git is QOjuye fhe Hles QYC Pxvpexly imported, Ada all xelakd Madule CY € Quk 6 Gtf pyopexly 40 CCue Co  AAticf 6c4 9uqtdida wii Jhocj fhl 0Gxb 9 Co de fhat QYc Jeacliog Y meySe Con Aecf CE Jhoulal Ytadlue fhe co oac E , Oaly Tra #u Gxonthe C^ be Merfed Wit Pxduc Fon ByoacL\n",
      "2/34\n",
      "\n",
      "--- PAGE 4 ---\n",
      "Q.No\n",
      "1,6\n",
      "Strugg' Alioq Lith maialaining Consisteacy i0 inkasksutf_ uye confguyatioc ^f a(cvoss mulliple e vironmeats\n",
      "Jasonsisloncy in maia 1-lataing jofsasfsaclux Confgurafions acc boss Mu  ltiple entyonmerd Could (eat fo icfuesr   lrke Syflen cocsn (ve Acteasabiltby Arbpl problemn$ , Protabi li  1 {scu& pey-lraankee \"dfues and Bad (Jt( expecienc 2 {c. Yaglerkaling Jakasbucfur CS 6de \" ( Iac) will Jolve Xhif LAf0n in consislo(y challeagc 2 Ouy iSsue= is ralled on multiple eau vonmeat toge Jafcuhuc luvr Q code esilf help Mai 4a, fne condukcat5 iQ ioPoufuctuve Coo Rgaxtionn OccYan te Mu(tiple eaviynme{ Chic chvecth Yesdue Pwbleru uif dlxntiny Qesponge Hine Mullple Qaui Yonm(9f jJJ06 scalcbi |iky {SJte ) aad pcxbyane ieue T6 imdeme[ Lelastsuthuvc O) Codkty Iku Nevelopes fean JhackI have Joodl kacslelse obou- huv code Hat con bz Modulieol , reuGabfe e-#tict 4 fo Ahe) Jhold Solio psiaciplu Aol ioplewwf Prxlsimaate +eda 56\" lxke CG chin} Qacf fnpltac+ tUey e78er(m = fcaut Jike\n",
      "3/34\n",
      "\n",
      "--- PAGE 5 ---\n",
      "QNo.\n",
      "Re #ekh an xeRetch _ hi Hr a ce mnod {Jq 67 Maq7 pyedlucb ma ke csaw feel like fh dala i Loaded icfaq toneocsly - Bu ro yalih the all cafa #al Cllv coufl Jer ir prc Roaded eho ao applic icshia 1J opentd , and thu dala V Ytfruhtd Gnd stxed ~heo UJfv Qpra} jhe_prtriclen paje _ 7his give 00 illetfon that fhe dafa 18 Woodtol ioctaneoculy (Jio9 Fht te choisil Thu probless 0t io ) consjsHer) 10 in Rastuachuk cn figuralion accon Mulfipk envsameah ccld be slueal 44105 fre (Lalautvuckun 0J Coca (Joc) tchaiquer\n",
      "4/34\n",
      "\n",
      "--- PAGE 6 ---\n",
      "QNo.\n",
      "20\n",
      "SubVexslea: CSVN) aod 6;4\n",
      "hey   archilecfuxal difexences 8 Subversio^ (SUN} System IS Oxn? kve Pile based Szfen _ Storu fhy each veysfon @X 4 Ilaley , Imi ted dline Conhi . lacks abilties like con fticf resolufion Oad rollbacks; Git is aq opea Souvce Vevsiun Contsol SoffJaye_ Back Version caa be sboved Q Q N(c Byanch Ualimiled cflline Ye 'Paxkzz Confsel Hove Secicl abilikes ku like conlficf reSolution dnq Arstaaf Yollbactr\n",
      "i) Jmpocl 0n Aeaos\n",
      "Using Subvexsion (SVN Gv 6i9 wil greaE ly impacf #e cal) Aeams Ck fhese tools Psy Veysro^ Co atso( 0a c collabxolion = 0) Uhile Usir) SUN SVN is pximilive\n",
      "5/34\n",
      "\n",
      "--- PAGE 7 ---\n",
      "Q No;\n",
      "Jle bosecl Vlrsion   confel Syslem. Usexz 0Y kac Face Q c(e85 Oy Oltodllock m0) iSfues _ chile #ryia9 Occess pctitelal lkcoa SvN is a ceatevlzedl Syten) chick could b2 VaqaroLlc f %e aflc kex; Out Mafacdl) propoy @ daly Coula be Cowcokdl 0t Foohecl ,\n",
      "b,) _ thile uSing Gil 9il Is a dislbuka Syutm/ So Mil Ovaly ho oc hoxity fwont OY {(Vafe cCces ) 76 Qafeclar person m teao 614 if highhh Jecuve and QeecQ Ayopey Gukhtk cafia^\n",
      "c4knce consalevo9 fne cdllaburottoa beftareo #l tam mlmbeyj ) Wirs 9i+ will Icp Yom and fimplifies fhu corplel cl chatins @nq (ade ~oocti)\n",
      "6/34\n",
      "\n",
      "--- PAGE 8 ---\n",
      "QNo:\n",
      "2,6 Bug  hualig9 od sQuesling chaqge Cansidering) Fhe CCJ thaf 0 cctical bvs ~0 Owhtd t MCin - byand) in tn lalet cuma' { aJJUMn; matn _ branch O^ 0 Pxoduthon byanch 7he Rixst Rnq 49 c cjkr KaosJ.a5 Ihu bu9 i0 fhe Ovudackion 9 ~il ~6/l buck M AY ducfiv f6 H px(viall< (onnit iS (trtain Hhot Ahe bug avds intclurecl iq Th Jatesf   (omm'+ Qil Simplo Fit fk Tqeb tak, Jik Ocfivit5 Moa ( 1ro9 Ocal choa5es moifvin 9: AVr y(verlio5 fh chons back Tn frcviows< 00mmit t Qedy c ckun ~il (onfimocs Seyve Thu Oylviou) VCupa AUs + 6Ci acx tk bcsle fk mudcle tha+ C aulol mnaJo = Bu; Tbb Ve0 Altol Aaol Vun the Acosh t6 be cyaa Ia Certa  n tx bw) Klo bren YeAolvtol Cves f4a5 Qst Qoykj eapected , Nenk Step \"6 dlamagl Contsel maju _ (uy M hese could Cquje kus e monc/a? olanag Qs thxush Yhe Jycfr 89' anok\n",
      "7/34\n",
      "\n",
      "--- PAGE 9 ---\n",
      "QNo\n",
      "Tyz h Tollback th2 daa5e madc ln clalbase Ls The (ug LJhe q &u QYe PG lly (extor fh Wve CveaV 0q5 Ifjae ~il fk Qvodlu cf 'pyjh ncin -Dvnch ,\n",
      "#is @bs Vev)   eoy tack change h eac) (ommit. 6i} majatan 0 Ycco rd c each cuuld honj? ( Fhak pexJo   hcus Mq d chrch Fvgkc^ Casy Jarale &d Y(Ve + # dhang:\n",
      "8/34\n",
      "\n",
      "--- PAGE 10 ---\n",
      "QNo.\n",
      ".6 'key componea b d _ chi-leclure c Docker\n",
      "W Caa coasides dockrr Q1 Q tsl #hat Staplfies f poxlabi= 1it5 isfues . (Jhile dlevelopin) Pxoject CJL uilf 4J€ m0n) packase Ono  }inallh butld # Final Code; Thq (odle is nedeel be Yuon/0^ voxious_ devices ard cli ffestaf Ontra fin9 Jyhta_ Tf U 0 lficf t Ve Conkigure fhu Prejec/ Rx each devu e Hkyc iS choc Ooc kp (Onu in , dec   ing dockw UC Cao (veafe on Cockec Conla n_ shich hac Gn drki GaG)\" Fha A Can 62 cauly Ce dl 0^ cilfeo mf evtces ~ifh ouf 0ny add: fioqdl Con Prg ura tion\n",
      "Oochev Igle\n",
      "(Docke, 2ag ine {S a JG - Pfacve ope licahbn thaf Cqo be dkyunbaded i 6 S6uv Jzfen Lhich Qxvide CLI conncnd Cin c Jatevface) Coakcf 1 (aocse fke dockey 0/ qo0/ Turnputev .\n",
      "9/34\n",
      "\n",
      "--- PAGE 11 ---\n",
      "QNo.\n",
      "Doche_Hlub\n",
      "Dockev hub fs 0 beb   dalbr cshxi< pu Jbu _ Sout docke ~lQosttorig 2hich Coafa (ae Con fain exa and Jnagus\n",
      "Cockings Continev N q box_,uhich caq have Qlockrr inagu toxedl del_iai4._ Y are  cied to Yuq / maqSe [cakcl ImGJe, Ooche Gnages Oockes inGgu ave Biaa/y Pck Cylatrd 59 Xockxs ensit Muk 0ut o6f ohle Pxjec/ enc d ed i0 /4\n",
      "Nehyayk and Vslu mu\n",
      "~Jhe tern pehsoak Anc( Volum Cued ja th decku 7 4ve aetyjacky jmasu called Voluny D hich Ci ) fsvcal G7 cLockev_hub\n",
      "10/34\n",
      "\n",
      "--- PAGE 12 ---\n",
      "QNo:\n",
      "3.b\n",
      "(ligroling Aom gonolilbic   ompliclbo Qxchilectyre\n",
      "MicYo  seyvice\n",
      "(onolilhic oppllta (ion is Qa Qpplica 6roa YhoF hos_6oly sigle blok Iakevac flos Hu Cet Mad @ dalbay . f+ Jodl hdve backraal JCVv( api'j acceclala) rf direcfl) pev lrms caltulaltu ^ and opeafea dafabye ead am MiCvo Sewite Gychitecfure _ Ihre Moy Sewic e bloc & anal each seyvi(c blac € wil ( Qevbto ol5 04 € Smple task . So Yaovck, t8 mlgval Maslifhi < aPplcafibo ink t6 0 Mtcyo scyvice architecfuve app ication, cing dkkev Coataing Jhe Rilossi25 Step t aw be xone, V) wvilin) (Iicro se Yvi ( 6s 2,0B   maajena/   wios 0n ORn  3/ Te Ho9 microseyvites 4/ Convaking (Ticvo Jeyviten 70 Sos; @ 5, Maoogin dockxv Gafoben , Yun #h Crtattel An49es 6 , Oepl.5in}\n",
      "11/34\n",
      "\n",
      "--- PAGE 13 ---\n",
      "QNo:\n",
      "(oslihhic Ioplicolroa\n",
      "taSer\n",
      "dahBar\n",
      "(dlafabase)\n",
      "micTo Sexuic\n",
      "mi(yoseyvite\n",
      "micrserJite\n",
      "ImggeL\n",
      "Ingr2\n",
      "Incs3\n",
      "Oocher Conlinw\n",
      "12/34\n",
      "\n",
      "--- PAGE 14 ---\n",
      "QNo.\n",
      "ta. Mauol_tesl plag lor 0 Complx 4eb Applicotion\n",
      "xek WS coniclev 0 complex Ejeb opplicalioa , ko Tvck 0 Fuliskck ~l cnelicaliog ted Qrg}ed monaSema } ho Yole bared Occ e5 TesF_plaq Meatiky fhle Cuer (xu 2 . 9deakify the ac(en @ 0 CocG USfly tpe 3. Qrqave Tet CC chaxf Gad tocluole_# abve G Cces & Godl Lail CQUU and Poss cojes 4 Jadluce edze cQies\n",
      "Nos Qef u6 jee Tt WJe cQe Ju maalal Aeoling 7h0u 0e fotal_c 5 _tye CNJ ey / {3Usex  admis `  StQu-oclnia ) O6g-mancg ey , Oyg WJey h #heJk are Mhet _ acrej Coealc_Ota Cyecdk 01 a(c WJi% aaq9e_Qrj ada ujin 4am5e Wt \"JJ py T F T F F Odoiin T F F F F JuQi adlmind T T T 7 7 T 6r5 - mqnfe F T T 049 F F F F WL F 13/34\n",
      "\n",
      "--- PAGE 15 ---\n",
      "Q No\n",
      "Dased 00 fh foblc above , UC (Q^ curite Test tdsle like\n",
      "TestoucSc SceaagYco UstvTye enptcte 1 Crcalc_0v9 Usc' 2. Cak 0x9 admiq 3 Ctlakc 0v Mgqoge,\n",
      "dus 8 Eall\n",
      "t F\n",
      "P\n",
      "Manvallyy Opra fhu scke Gndl Jtg\"n Q difkevcat rulu and Ucdtdah fhetof ~ou tolle 65_Bcdl m19 bvf'\n",
      "14/34\n",
      "\n",
      "--- PAGE 16 ---\n",
      "QNo\n",
      "+6\n",
      "Orpvrative tulplan dor 0ty feafure\n",
      "do develop 0 ComPvehcasiv fesl_plan t6 easaye Full covcwse newj fealure in an opplicokoa, Afis mndalory iadude edge cases aad pokeafial Renlurc Pobh Mate Jhuyc then @real a1( bug' cd 24 0 ytad be Qxduted , Fidlls ~c shyld Ytd fv Yeuiyeaeaf FR prajecls Nkuj featuv Unclextaad 21 FuacHionaliky- ft help Jiool edSe cqst ~hilc ~eting Pesforms Uaif tesliay ialgrclloa telia9 / Qc fuqa feokio9 Loitl # x (0sy iacludecl cilk # eds CQJB Ajo CUe' Twp - Yocna Od/ (el(zaIka m 4p QPpyache Male Jhtan Mhete Ovcnu 0n5 bw)' ond uqeme fol bchaviouv 0}te Jeofuyt . Moki^9 thwve th Rea luvs mee/f Ysuiyc(ah Onq Cayl , cui 64 01 iour 15 OKy MGl9 Dyioytty fo Xevclep (onprchjiu e feal_plaal fo (O/uv tx Eu coVCrcSe c_ # nlv Jeafurea 10 Q 0 Gpplitalion\n",
      "15/34\n",
      "\n",
      "--- PAGE 17 ---\n",
      "Q No;\n",
      "6.0\n",
      "Amazo^ Elasttc 6rpcti /9 ia Jewvile Arovded b5 Amao^ LJeb Jwite ( Aws) , Gyhich Srli pyovide 0' Virtuol 6Machine Oa Ag $ cloud Th Osc tvu al Ec Swie Qik YCJe Vucd tasfance , 00 - demurdl Iotance Spot inslanck . 0+ i$ iripo ) Yloa k 16 chte Mhu Mosk_ stable Qactagc Modef haed 6^ H Cje) € 42 Oo cue SJil be sein? Ca em 'Ichol lcvge Jumben 0^ 0 UV Mloalh billn; 2C2 Resevucd mhb Ioufaa €c Ook scdloble 0a4  JcifaSlc@ Mii_eyucv chec_Bael Ost ewpeckd On_olemaacl Sadtn (e Hlevt 7F ic_ScalaSk baed 04 #z ta-lfic th Mtovh ancl bind ials Jaccajes Spot -on Jaataa € 4ese Juv Jevvcr Ir alyeads J cslecl eifl Xop halcvavc , Yhv 1S efficccat 70 5 Gpp em Occf , Coafincou #aflic\n",
      "16/34\n",
      "\n",
      "--- PAGE 18 ---\n",
      "QNo.\n",
      "6b,\n",
      "Advaabge = 4_cleolyin;\n",
      "Dockes (a haberrz\n",
      "Oock (oataine= Oyc ealh/h Qurta blk , no Oeed iolall pacEaSe al_&_t Jefup\n",
      "Gash acces\n",
      "W tt\n",
      "Jtoplxi Hz.\n",
      "Sas RAplttaktum packoging Stcpk deqasccy nqaqSenaf 7 Cv) It 8ckez i0GSc ab havs cli Qeecleo Qcckase\n",
      "&ay] clplo) QccY0) dilesa f QV (Knmel, Aeke Ljrcldus / Equh Gad Mlacof\n",
      "17/34\n",
      "\n",
      "--- PAGE 19 ---\n",
      "QNo:\n",
      "18/34\n",
      "\n",
      "--- PAGE 20 ---\n",
      "QNo.\n",
      "19/34\n",
      "\n",
      "--- PAGE 21 ---\n",
      "QNo:\n",
      "20/34\n",
      "\n",
      "--- PAGE 22 ---\n",
      "QNo.\n",
      "21/34\n",
      "\n",
      "--- PAGE 23 ---\n",
      "Q No:\n",
      "22/34\n",
      "\n",
      "--- PAGE 24 ---\n",
      "Fc0 Li0\n",
      "QNo\n",
      "23/34\n",
      "\n",
      "--- PAGE 25 ---\n",
      "QNo\n",
      "24/34\n",
      "\n",
      "--- PAGE 26 ---\n",
      "QNo.\n",
      "25/34\n",
      "Vonl\n",
      "\n",
      "--- PAGE 27 ---\n",
      "QNo:\n",
      "26/34\n",
      "\n",
      "--- PAGE 28 ---\n",
      "QNo.\n",
      "27/34\n",
      "Ji\n",
      "\n",
      "--- PAGE 29 ---\n",
      "QNo\n",
      "28/34\n",
      "\n",
      "--- PAGE 30 ---\n",
      "QNo.\n",
      "29/34\n",
      "\n",
      "--- PAGE 31 ---\n",
      "QNo.\n",
      "30/34\n",
      "\n",
      "--- PAGE 32 ---\n",
      "QNo:\n",
      "31/34\n",
      "1\n",
      "\n",
      "--- PAGE 33 ---\n",
      "QNo\n",
      "32/34\n",
      "\n",
      "--- PAGE 34 ---\n",
      "QNo_\n",
      "33/34\n",
      "'844\n",
      "\n",
      "--- PAGE 35 ---\n",
      "ROUGH WORK\n",
      "Content written here will not be considered for valuation\n",
      "34/34\n"
     ]
    }
   ],
   "source": [
    "print(output[\"combined_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67a1a161",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\PROGRAMS\\AI\\evaluate.ai\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7424fad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=\"API-KEY\")\n",
    "model = genai.GenerativeModel(\"gemini-2.5-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d9702e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "You are given raw OCR text from an exam paper.\n",
    "\n",
    "Your task:\n",
    "1. Clean the OCR text to make it readable.\n",
    "2. Identify each question and the student’s answer.\n",
    "3. Extract the answers into structured JSON in this format:\n",
    "{\n",
    "  \"answers\": [\n",
    "    {\n",
    "      \"number\": \"1.a\",\n",
    "      \"question\": \"Question text here\",\n",
    "      \"text\": \"Student's answer text here\",\n",
    "      \"marks\": based on the max score of question,\n",
    "      \"remark\": \"Reason for deduction or comment\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "4. For evaluation: \n",
    "   - Award marks based on correctness and completeness.\n",
    "   - Provide remarks if marks are deducted.\n",
    "\n",
    "Return **only valid JSON** without additional text.\n",
    "\n",
    "Here is the OCR text:\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17a77e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "\n",
    "pdf_file = f\"test-material/qps/{sub}_qp.pdf\"\n",
    "qp = \"\"\n",
    "\n",
    "with open(pdf_file, \"rb\") as f:\n",
    "    reader = PyPDF2.PdfReader(f)\n",
    "    for page in reader.pages:\n",
    "        qp += page.extract_text() + \"\\n\"\n",
    "\n",
    "with open(\"question_paper.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(qp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b82bd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_paper = f\"\"\"\n",
    "=========================================================\n",
    "Here is the question paper:\n",
    "{qp[470:]}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a3c5bc95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are given raw OCR text from an exam paper.\n",
      "\n",
      "Your task:\n",
      "1. Clean the OCR text to make it readable.\n",
      "2. Identify each question and the student’s answer.\n",
      "3. Extract the answers into structured JSON in this format:\n",
      "{\n",
      "  \"answers\": [\n",
      "    {\n",
      "      \"number\": \"1.a\",\n",
      "      \"question\": \"Question text here\",\n",
      "      \"text\": \"Student's answer text here\",\n",
      "      \"marks\": based on the max score of question,\n",
      "      \"remark\": \"Reason for deduction or comment\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "4. For evaluation: \n",
      "   - Award marks based on correctness and completeness.\n",
      "   - Provide remarks if marks are deducted.\n",
      "\n",
      "Return **only valid JSON** without additional text.\n",
      "\n",
      "Here is the OCR text:\n",
      "--- PAGE 1 ---\n",
      "INSTITUTE OF AERONAUTICAL ENGINEERING (Autonomous) 1 Dundigal 500 043, Hyderabad, Telangana\n",
      "Examinations Control Office\n",
      "Examination B TECH  VI SEMESTER END EXAMINATIONS REGULAR JUNE 2025 REG UG20\n",
      "Month & Year 1-Jun\n",
      "Date 20/06/2025\n",
      "Course Name DEVOPS\n",
      "Course Code ACSC42\n",
      "E-Code 6775\n",
      "Instructions to Evaluators Evaluators should spend at least 3-5 minutes on one answer booklet during the evaluation. Evaluators should cross check that marks are allotted for all the attempted questions. The marks   should be  assigned  fairly according to the mark   distribution specified in the scheme of evaluation. For questions that were attempted incorrectly, evaluators are required to award zero marks. The evaluator must give proper justification in case of any mistakes identified in the marks provided.\n",
      "1\n",
      "\n",
      "--- PAGE 2 ---\n",
      "START WRITING FROM HERE\n",
      "QNo.\n",
      "1.0 Brnching   qnd Mzig ing i0 Sil\n",
      "Qil is an open? Souyce disHi buted Veysio) conkol plaHfxn Ihq 4 Ovovidu Vori fus SqYui ( (es, 9il allows, Gs fo crcate Mullipk Qumber brnches fct fbe same repostloyy  xeposi {oyy 1S 0 cUdle bafe gien Pyqjeck. Theye Coa bc 0uny bxanche {o 0 Ye pos' bovy ~htch Wi |l be maltaneo bs diPexent teans; Suppose Ref WJ conf ale Product ehich is 60 Pkduchzon And ine Compoo5 Donf adal mulfiple idepnolkat Realuye Iol py ducf_ Heve the (ompony Lil cxa te One 06 bxonch Rr ea ck Jealuve each Ratuye Rs idpea &le: Qod 8oes + rel5 60 0 Ipev nes Jaluye , Heee each branch i5 dested aad build Thea Ih 060 (lo (allhc ) Ye rpostl (torh) will havl Ihe au fhaxi /y mkys< thest bxonchu ucH fLe Qxudu ctio ^ boonch. Aadl ~h ayfhov is vexponi 61 & 6 8, occepling: fhe pu (r YesGesd ~ox ku blonch aad on/5 Inea i9 i sgk to delek_Ih JacAuvt bxoncL 1/34\n",
      "\n",
      "--- PAGE 3 ---\n",
      "Q.No.\n",
      "(ei) katuic  kol Reoluve (B2) 6' J gronhiqs\n",
      "Pyoduc Idion &ranch\n",
      "negin) 83 #\".ti;\n",
      "6761c6,5 0, katuu\" (Bz)\n",
      "Neyjin) B2 Jil Plec\n",
      "Rs\n",
      "~3f\" erede tlie+ edlky bgb, Ihu producHia pranch win hav # (C4) Raluyu % Gvonches . Magoging Eoalicks Eonlhcb SdMC tine Occuv ah You aye Qahins (mexslo5 thc branches: Th bet pracktes fv mcncqing confit iq Git is QOjuye fhe Hles QYC Pxvpexly imported, Ada all xelakd Madule CY € Quk 6 Gtf pyopexly 40 CCue Co  AAticf 6c4 9uqtdida wii Jhocj fhl 0Gxb 9 Co de fhat QYc Jeacliog Y meySe Con Aecf CE Jhoulal Ytadlue fhe co oac E , Oaly Tra #u Gxonthe C^ be Merfed Wit Pxduc Fon ByoacL\n",
      "2/34\n",
      "\n",
      "--- PAGE 4 ---\n",
      "Q.No\n",
      "1,6\n",
      "Strugg' Alioq Lith maialaining Consisteacy i0 inkasksutf_ uye confguyatioc ^f a(cvoss mulliple e vironmeats\n",
      "Jasonsisloncy in maia 1-lataing jofsasfsaclux Confgurafions acc boss Mu  ltiple entyonmerd Could (eat fo icfuesr   lrke Syflen cocsn (ve Acteasabiltby Arbpl problemn$ , Protabi li  1 {scu& pey-lraankee \"dfues and Bad (Jt( expecienc 2 {c. Yaglerkaling Jakasbucfur CS 6de \" ( Iac) will Jolve Xhif LAf0n in consislo(y challeagc 2 Ouy iSsue= is ralled on multiple eau vonmeat toge Jafcuhuc luvr Q code esilf help Mai 4a, fne condukcat5 iQ ioPoufuctuve Coo Rgaxtionn OccYan te Mu(tiple eaviynme{ Chic chvecth Yesdue Pwbleru uif dlxntiny Qesponge Hine Mullple Qaui Yonm(9f jJJ06 scalcbi |iky {SJte ) aad pcxbyane ieue T6 imdeme[ Lelastsuthuvc O) Codkty Iku Nevelopes fean JhackI have Joodl kacslelse obou- huv code Hat con bz Modulieol , reuGabfe e-#tict 4 fo Ahe) Jhold Solio psiaciplu Aol ioplewwf Prxlsimaate +eda 56\" lxke CG chin} Qacf fnpltac+ tUey e78er(m = fcaut Jike\n",
      "3/34\n",
      "\n",
      "--- PAGE 5 ---\n",
      "QNo.\n",
      "Re #ekh an xeRetch _ hi Hr a ce mnod {Jq 67 Maq7 pyedlucb ma ke csaw feel like fh dala i Loaded icfaq toneocsly - Bu ro yalih the all cafa #al Cllv coufl Jer ir prc Roaded eho ao applic icshia 1J opentd , and thu dala V Ytfruhtd Gnd stxed ~heo UJfv Qpra} jhe_prtriclen paje _ 7his give 00 illetfon that fhe dafa 18 Woodtol ioctaneoculy (Jio9 Fht te choisil Thu probless 0t io ) consjsHer) 10 in Rastuachuk cn figuralion accon Mulfipk envsameah ccld be slueal 44105 fre (Lalautvuckun 0J Coca (Joc) tchaiquer\n",
      "4/34\n",
      "\n",
      "--- PAGE 6 ---\n",
      "QNo.\n",
      "20\n",
      "SubVexslea: CSVN) aod 6;4\n",
      "hey   archilecfuxal difexences 8 Subversio^ (SUN} System IS Oxn? kve Pile based Szfen _ Storu fhy each veysfon @X 4 Ilaley , Imi ted dline Conhi . lacks abilties like con fticf resolufion Oad rollbacks; Git is aq opea Souvce Vevsiun Contsol SoffJaye_ Back Version caa be sboved Q Q N(c Byanch Ualimiled cflline Ye 'Paxkzz Confsel Hove Secicl abilikes ku like conlficf reSolution dnq Arstaaf Yollbactr\n",
      "i) Jmpocl 0n Aeaos\n",
      "Using Subvexsion (SVN Gv 6i9 wil greaE ly impacf #e cal) Aeams Ck fhese tools Psy Veysro^ Co atso( 0a c collabxolion = 0) Uhile Usir) SUN SVN is pximilive\n",
      "5/34\n",
      "\n",
      "--- PAGE 7 ---\n",
      "Q No;\n",
      "Jle bosecl Vlrsion   confel Syslem. Usexz 0Y kac Face Q c(e85 Oy Oltodllock m0) iSfues _ chile #ryia9 Occess pctitelal lkcoa SvN is a ceatevlzedl Syten) chick could b2 VaqaroLlc f %e aflc kex; Out Mafacdl) propoy @ daly Coula be Cowcokdl 0t Foohecl ,\n",
      "b,) _ thile uSing Gil 9il Is a dislbuka Syutm/ So Mil Ovaly ho oc hoxity fwont OY {(Vafe cCces ) 76 Qafeclar person m teao 614 if highhh Jecuve and QeecQ Ayopey Gukhtk cafia^\n",
      "c4knce consalevo9 fne cdllaburottoa beftareo #l tam mlmbeyj ) Wirs 9i+ will Icp Yom and fimplifies fhu corplel cl chatins @nq (ade ~oocti)\n",
      "6/34\n",
      "\n",
      "--- PAGE 8 ---\n",
      "QNo:\n",
      "2,6 Bug  hualig9 od sQuesling chaqge Cansidering) Fhe CCJ thaf 0 cctical bvs ~0 Owhtd t MCin - byand) in tn lalet cuma' { aJJUMn; matn _ branch O^ 0 Pxoduthon byanch 7he Rixst Rnq 49 c cjkr KaosJ.a5 Ihu bu9 i0 fhe Ovudackion 9 ~il ~6/l buck M AY ducfiv f6 H px(viall< (onnit iS (trtain Hhot Ahe bug avds intclurecl iq Th Jatesf   (omm'+ Qil Simplo Fit fk Tqeb tak, Jik Ocfivit5 Moa ( 1ro9 Ocal choa5es moifvin 9: AVr y(verlio5 fh chons back Tn frcviows< 00mmit t Qedy c ckun ~il (onfimocs Seyve Thu Oylviou) VCupa AUs + 6Ci acx tk bcsle fk mudcle tha+ C aulol mnaJo = Bu; Tbb Ve0 Altol Aaol Vun the Acosh t6 be cyaa Ia Certa  n tx bw) Klo bren YeAolvtol Cves f4a5 Qst Qoykj eapected , Nenk Step \"6 dlamagl Contsel maju _ (uy M hese could Cquje kus e monc/a? olanag Qs thxush Yhe Jycfr 89' anok\n",
      "7/34\n",
      "\n",
      "--- PAGE 9 ---\n",
      "QNo\n",
      "Tyz h Tollback th2 daa5e madc ln clalbase Ls The (ug LJhe q &u QYe PG lly (extor fh Wve CveaV 0q5 Ifjae ~il fk Qvodlu cf 'pyjh ncin -Dvnch ,\n",
      "#is @bs Vev)   eoy tack change h eac) (ommit. 6i} majatan 0 Ycco rd c each cuuld honj? ( Fhak pexJo   hcus Mq d chrch Fvgkc^ Casy Jarale &d Y(Ve + # dhang:\n",
      "8/34\n",
      "\n",
      "--- PAGE 10 ---\n",
      "QNo.\n",
      ".6 'key componea b d _ chi-leclure c Docker\n",
      "W Caa coasides dockrr Q1 Q tsl #hat Staplfies f poxlabi= 1it5 isfues . (Jhile dlevelopin) Pxoject CJL uilf 4J€ m0n) packase Ono  }inallh butld # Final Code; Thq (odle is nedeel be Yuon/0^ voxious_ devices ard cli ffestaf Ontra fin9 Jyhta_ Tf U 0 lficf t Ve Conkigure fhu Prejec/ Rx each devu e Hkyc iS choc Ooc kp (Onu in , dec   ing dockw UC Cao (veafe on Cockec Conla n_ shich hac Gn drki GaG)\" Fha A Can 62 cauly Ce dl 0^ cilfeo mf evtces ~ifh ouf 0ny add: fioqdl Con Prg ura tion\n",
      "Oochev Igle\n",
      "(Docke, 2ag ine {S a JG - Pfacve ope licahbn thaf Cqo be dkyunbaded i 6 S6uv Jzfen Lhich Qxvide CLI conncnd Cin c Jatevface) Coakcf 1 (aocse fke dockey 0/ qo0/ Turnputev .\n",
      "9/34\n",
      "\n",
      "--- PAGE 11 ---\n",
      "QNo.\n",
      "Doche_Hlub\n",
      "Dockev hub fs 0 beb   dalbr cshxi< pu Jbu _ Sout docke ~lQosttorig 2hich Coafa (ae Con fain exa and Jnagus\n",
      "Cockings Continev N q box_,uhich caq have Qlockrr inagu toxedl del_iai4._ Y are  cied to Yuq / maqSe [cakcl ImGJe, Ooche Gnages Oockes inGgu ave Biaa/y Pck Cylatrd 59 Xockxs ensit Muk 0ut o6f ohle Pxjec/ enc d ed i0 /4\n",
      "Nehyayk and Vslu mu\n",
      "~Jhe tern pehsoak Anc( Volum Cued ja th decku 7 4ve aetyjacky jmasu called Voluny D hich Ci ) fsvcal G7 cLockev_hub\n",
      "10/34\n",
      "\n",
      "--- PAGE 12 ---\n",
      "QNo:\n",
      "3.b\n",
      "(ligroling Aom gonolilbic   ompliclbo Qxchilectyre\n",
      "MicYo  seyvice\n",
      "(onolilhic oppllta (ion is Qa Qpplica 6roa YhoF hos_6oly sigle blok Iakevac flos Hu Cet Mad @ dalbay . f+ Jodl hdve backraal JCVv( api'j acceclala) rf direcfl) pev lrms caltulaltu ^ and opeafea dafabye ead am MiCvo Sewite Gychitecfure _ Ihre Moy Sewic e bloc & anal each seyvi(c blac € wil ( Qevbto ol5 04 € Smple task . So Yaovck, t8 mlgval Maslifhi < aPplcafibo ink t6 0 Mtcyo scyvice architecfuve app ication, cing dkkev Coataing Jhe Rilossi25 Step t aw be xone, V) wvilin) (Iicro se Yvi ( 6s 2,0B   maajena/   wios 0n ORn  3/ Te Ho9 microseyvites 4/ Convaking (Ticvo Jeyviten 70 Sos; @ 5, Maoogin dockxv Gafoben , Yun #h Crtattel An49es 6 , Oepl.5in}\n",
      "11/34\n",
      "\n",
      "--- PAGE 13 ---\n",
      "QNo:\n",
      "(oslihhic Ioplicolroa\n",
      "taSer\n",
      "dahBar\n",
      "(dlafabase)\n",
      "micTo Sexuic\n",
      "mi(yoseyvite\n",
      "micrserJite\n",
      "ImggeL\n",
      "Ingr2\n",
      "Incs3\n",
      "Oocher Conlinw\n",
      "12/34\n",
      "\n",
      "--- PAGE 14 ---\n",
      "QNo.\n",
      "ta. Mauol_tesl plag lor 0 Complx 4eb Applicotion\n",
      "xek WS coniclev 0 complex Ejeb opplicalioa , ko Tvck 0 Fuliskck ~l cnelicaliog ted Qrg}ed monaSema } ho Yole bared Occ e5 TesF_plaq Meatiky fhle Cuer (xu 2 . 9deakify the ac(en @ 0 CocG USfly tpe 3. Qrqave Tet CC chaxf Gad tocluole_# abve G Cces & Godl Lail CQUU and Poss cojes 4 Jadluce edze cQies\n",
      "Nos Qef u6 jee Tt WJe cQe Ju maalal Aeoling 7h0u 0e fotal_c 5 _tye CNJ ey / {3Usex  admis `  StQu-oclnia ) O6g-mancg ey , Oyg WJey h #heJk are Mhet _ acrej Coealc_Ota Cyecdk 01 a(c WJi% aaq9e_Qrj ada ujin 4am5e Wt \"JJ py T F T F F Odoiin T F F F F JuQi adlmind T T T 7 7 T 6r5 - mqnfe F T T 049 F F F F WL F 13/34\n",
      "\n",
      "--- PAGE 15 ---\n",
      "Q No\n",
      "Dased 00 fh foblc above , UC (Q^ curite Test tdsle like\n",
      "TestoucSc SceaagYco UstvTye enptcte 1 Crcalc_0v9 Usc' 2. Cak 0x9 admiq 3 Ctlakc 0v Mgqoge,\n",
      "dus 8 Eall\n",
      "t F\n",
      "P\n",
      "Manvallyy Opra fhu scke Gndl Jtg\"n Q difkevcat rulu and Ucdtdah fhetof ~ou tolle 65_Bcdl m19 bvf'\n",
      "14/34\n",
      "\n",
      "--- PAGE 16 ---\n",
      "QNo\n",
      "+6\n",
      "Orpvrative tulplan dor 0ty feafure\n",
      "do develop 0 ComPvehcasiv fesl_plan t6 easaye Full covcwse newj fealure in an opplicokoa, Afis mndalory iadude edge cases aad pokeafial Renlurc Pobh Mate Jhuyc then @real a1( bug' cd 24 0 ytad be Qxduted , Fidlls ~c shyld Ytd fv Yeuiyeaeaf FR prajecls Nkuj featuv Unclextaad 21 FuacHionaliky- ft help Jiool edSe cqst ~hilc ~eting Pesforms Uaif tesliay ialgrclloa telia9 / Qc fuqa feokio9 Loitl # x (0sy iacludecl cilk # eds CQJB Ajo CUe' Twp - Yocna Od/ (el(zaIka m 4p QPpyache Male Jhtan Mhete Ovcnu 0n5 bw)' ond uqeme fol bchaviouv 0}te Jeofuyt . Moki^9 thwve th Rea luvs mee/f Ysuiyc(ah Onq Cayl , cui 64 01 iour 15 OKy MGl9 Dyioytty fo Xevclep (onprchjiu e feal_plaal fo (O/uv tx Eu coVCrcSe c_ # nlv Jeafurea 10 Q 0 Gpplitalion\n",
      "15/34\n",
      "\n",
      "--- PAGE 17 ---\n",
      "Q No;\n",
      "6.0\n",
      "Amazo^ Elasttc 6rpcti /9 ia Jewvile Arovded b5 Amao^ LJeb Jwite ( Aws) , Gyhich Srli pyovide 0' Virtuol 6Machine Oa Ag $ cloud Th Osc tvu al Ec Swie Qik YCJe Vucd tasfance , 00 - demurdl Iotance Spot inslanck . 0+ i$ iripo ) Yloa k 16 chte Mhu Mosk_ stable Qactagc Modef haed 6^ H Cje) € 42 Oo cue SJil be sein? Ca em 'Ichol lcvge Jumben 0^ 0 UV Mloalh billn; 2C2 Resevucd mhb Ioufaa €c Ook scdloble 0a4  JcifaSlc@ Mii_eyucv chec_Bael Ost ewpeckd On_olemaacl Sadtn (e Hlevt 7F ic_ScalaSk baed 04 #z ta-lfic th Mtovh ancl bind ials Jaccajes Spot -on Jaataa € 4ese Juv Jevvcr Ir alyeads J cslecl eifl Xop halcvavc , Yhv 1S efficccat 70 5 Gpp em Occf , Coafincou #aflic\n",
      "16/34\n",
      "\n",
      "--- PAGE 18 ---\n",
      "QNo.\n",
      "6b,\n",
      "Advaabge = 4_cleolyin;\n",
      "Dockes (a haberrz\n",
      "Oock (oataine= Oyc ealh/h Qurta blk , no Oeed iolall pacEaSe al_&_t Jefup\n",
      "Gash acces\n",
      "W tt\n",
      "Jtoplxi Hz.\n",
      "Sas RAplttaktum packoging Stcpk deqasccy nqaqSenaf 7 Cv) It 8ckez i0GSc ab havs cli Qeecleo Qcckase\n",
      "&ay] clplo) QccY0) dilesa f QV (Knmel, Aeke Ljrcldus / Equh Gad Mlacof\n",
      "17/34\n",
      "\n",
      "--- PAGE 19 ---\n",
      "QNo:\n",
      "18/34\n",
      "\n",
      "--- PAGE 20 ---\n",
      "QNo.\n",
      "19/34\n",
      "\n",
      "--- PAGE 21 ---\n",
      "QNo:\n",
      "20/34\n",
      "\n",
      "--- PAGE 22 ---\n",
      "QNo.\n",
      "21/34\n",
      "\n",
      "--- PAGE 23 ---\n",
      "Q No:\n",
      "22/34\n",
      "\n",
      "--- PAGE 24 ---\n",
      "Fc0 Li0\n",
      "QNo\n",
      "23/34\n",
      "\n",
      "--- PAGE 25 ---\n",
      "QNo\n",
      "24/34\n",
      "\n",
      "--- PAGE 26 ---\n",
      "QNo.\n",
      "25/34\n",
      "Vonl\n",
      "\n",
      "--- PAGE 27 ---\n",
      "QNo:\n",
      "26/34\n",
      "\n",
      "--- PAGE 28 ---\n",
      "QNo.\n",
      "27/34\n",
      "Ji\n",
      "\n",
      "--- PAGE 29 ---\n",
      "QNo\n",
      "28/34\n",
      "\n",
      "--- PAGE 30 ---\n",
      "QNo.\n",
      "29/34\n",
      "\n",
      "--- PAGE 31 ---\n",
      "QNo.\n",
      "30/34\n",
      "\n",
      "--- PAGE 32 ---\n",
      "QNo:\n",
      "31/34\n",
      "1\n",
      "\n",
      "--- PAGE 33 ---\n",
      "QNo\n",
      "32/34\n",
      "\n",
      "--- PAGE 34 ---\n",
      "QNo_\n",
      "33/34\n",
      "'844\n",
      "\n",
      "--- PAGE 35 ---\n",
      "ROUGH WORK\n",
      "Content written here will not be considered for valuation\n",
      "34/34\n",
      "=========================================================\n",
      "Here is the question paper:\n",
      "nswered in one place only\n",
      "MODULE – I\n",
      "1.(a)Explain the process of branching and merging in Git. What are the best practices for managing\n",
      "branches and resolving conflicts? [BL: Understand| CO: 1|Marks: 7]\n",
      "(b)Your team is struggling with maintaining consistency in infrastructure configurations across mul-\n",
      "tiple environments. How would you implement infrastructure as Code (IaC) to address this\n",
      "challenge? [BL: Apply| CO: 1|Marks: 7]\n",
      "MODULE – II\n",
      "2.(a)Discuss the key architectural differences between SVN and Git. How do these differences impact\n",
      "the way teams use these tools for version control and collaboration?\n",
      "[BL: Understand| CO: 2|Marks: 7]\n",
      "(b)A critical bug was introduced in the latest commit on the main branch. How would you use Git\n",
      "to identify the commit that introduced the bug and revert the changes?\n",
      "[BL: Apply| CO: 2|Marks: 7]\n",
      "MODULE – III\n",
      "3.(a)Discuss the key components and architecture of docker, including docker engine, docker hub,\n",
      "docker images, containers, networks, and volumes. [BL: Understand| CO: 3|Marks: 7]\n",
      "(b)Your team is migrating an existing monolithic application to microservices architecture using\n",
      "docker containers. Outline the steps and considerations for breaking down the monolith into\n",
      "smaller, independently deployable containers. [BL: Apply| CO: 3|Marks: 7]\n",
      "4.(a)Describe the security considerations and best practices for docker containers and dockerized\n",
      "applications, covering topics such as container isolation, image security, network security, and\n",
      "vulnerability management. [BL: Understand| CO: 4|Marks: 7]\n",
      "(b)You need to ensure high availability and fault tolerance for a Docker Swarm cluster hosting\n",
      "critical applications. Outline the strategies and tools you would use to achieve these objectives.\n",
      "[BL: Understand| CO: 4|Marks: 7]\n",
      "Page 1 of 2\n",
      "MODULE – IV\n",
      "5.(a)Discuss the process of creating and managing Chef cookbooks. Include the steps involved in\n",
      "writing recipes, defining attributes, and testing cookbooks before deployment.\n",
      "[BL: Understand| CO: 5|Marks: 7]\n",
      "(b)Explain the role of chef in cloud provisioning and configuration management. Discuss how Chef\n",
      "automates infrastructure deployment and ensures consistency across environments.\n",
      "[BL: Understand| CO: 5|Marks: 7]\n",
      "6.(a)Compare EC2 reserved instances, on-demand instances and spot instances in terms of pricing\n",
      "models, cost optimization strategies and use cases for each type.\n",
      "[BL: Understand| CO: 5|Marks: 7]\n",
      "(b)List the advantages of deploying applications in docker containers. Discuss how docker simplifies\n",
      "application packaging, dependency management, and deployment across different environments.\n",
      "[BL: Understand| CO: 5|Marks: 7]\n",
      "MODULE – V\n",
      "7.(a)Outline the process of creating a manual test plan for a complex web application. What key\n",
      "elements should be included, and how would you ensure the plan is thorough and effective?\n",
      "[BL: Understand| CO: 6|Marks: 7]\n",
      "(b)How would you develop a comprehensive test plan to ensure full coverage of a new feature in\n",
      "your application, including edge cases and potential failure points? [BL: Apply| CO: 6|Marks: 7]\n",
      "8.(a)Mention the key considerations when creating docker containers for automated testing. Discuss\n",
      "how you would handle dependencies and configuration. [BL: Understand| CO: 6|Marks: 7]\n",
      "(b)Describe how you would implement automated integration tests for a microservices architecture.\n",
      "What tools would you use, and how would you ensure data consistency across tests?\n",
      "[BL: Understand| CO: 6|Marks: 7]\n",
      " \u000e \u000e \u0000\n",
      "Page 2 of 2\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_prompt = prompt + output[\"combined_text\"] + q_paper\n",
    "print(final_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "079bfe85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16007"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b4248286",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.generate_content(final_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c00b0813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"answers\": [\n",
      "    {\n",
      "      \"number\": \"1.a\",\n",
      "      \"question\": \"Explain the process of branching and merging in Git. What are the best practices for managing branches and resolving conflicts?\",\n",
      "      \"text\": \"Branching and Merging in Git. Git is an open-source distributed version control platform that provides various services. Git allows us to create multiple branches for the same repository. A repository is a codebase given for a project. There can be many branches for a repository which will be maintained by different teams. Suppose a company wants to add a product which is in production and the company wants to add multiple independent features for the product. Here, the company will create one new branch for each feature. Each feature is independent. For example, if a bug goes into release 0.1 for new features, here each branch is tested and built. The main (or 'production') repository will have the authority to merge these branches with the production branch. And the authority is responsible for accepting the pull requests for that branch, and only then is it safe to delete the feature branch.\\n\\n[Diagram: Feature (B1), Feature (B2) -> Production Branch. begin) B3. (various arrows and text like git push, merge conflicts)]\\n\\nManaging Conflicts: Conflicts sometimes occur when you are merging branches. The best practices for managing conflicts in Git is to ensure the files are properly imported. Add all related modules correctly. To resolve conflicts, you should re-read the code. Only the bug-free branches can be merged with the production branch.\",\n",
      "      \"marks\": 5,\n",
      "      \"remark\": \"Good explanation of branching and merging with a clear example. The description of conflict resolution best practices is somewhat generic and lacks specific Git commands or advanced strategies like `git mergetool` or `git rebase`.\"\n",
      "    },\n",
      "    {\n",
      "      \"number\": \"1.b\",\n",
      "      \"question\": \"Your team is struggling with maintaining consistency in infrastructure configurations across multiple environments. How would you implement infrastructure as Code (IaC) to address this challenge?\",\n",
      "      \"text\": \"Struggling with maintaining consistency in infrastructure configurations across multiple environments. Inconsistency in maintaining infrastructure configurations across multiple environments could lead to issues like system crashes, accessibility problems, reliability issues, performance issues, and bad user experience. Implementing Infrastructure as Code (IaC) will solve this inconsistency challenge. Our issue is to deploy on multiple environments. Infrastructure as Code will help maintain the configurations in infrastructure across multiple environments, which directly resolves problems with varying response times, multiple environment scalability issues, and performance issues. To implement Infrastructure as Code, developers should have good knowledge about how code can be modularized, reusable, and structured. They should follow SOLID principles and implement practices like caching and implicit dependencies. For example, 'refresh on refresh' (this seems like a random example, perhaps meant to illustrate a concept but is poorly explained). This is a common method for many products to make the user feel like the data is loaded instantaneously. But in reality, all data will load in parts, which is pre-loaded when the application is opened, and the data is refreshed and stored when the user opens the particular page. This gives the illusion that the data is loaded instantaneously. This problem of inconsistency in infrastructure configuration across multiple environments could be solved using the Infrastructure as Code (IaC) technique.\",\n",
      "      \"marks\": 4,\n",
      "      \"remark\": \"Correctly identifies the problem and proposes IaC as the solution, listing relevant benefits and general principles for developers. However, the lengthy 'refresh on refresh' example is completely irrelevant to IaC and infrastructure consistency, distracting from the core answer. It also doesn't mention specific IaC tools (e.g., Terraform, Ansible, Chef, Puppet) which would strengthen the implementation aspect.\"\n",
      "    },\n",
      "    {\n",
      "      \"number\": \"2.a\",\n",
      "      \"question\": \"Discuss the key architectural differences between SVN and Git. How do these differences impact the way teams use these tools for version control and collaboration?\",\n",
      "      \"text\": \"Subversion (SVN) and Git. Key architectural differences: Subversion (SVN) System is a file-based system. It stores each version as a whole file. Limited offline control. Lacks abilities like conflict resolution and rollbacks. Git is an open-source Version Control Software. Each version can be stored in a new branch. Unlimited offline control. Has special abilities like conflict resolution and instant rollbacks.\\n\\nImpact on Teams: Using Subversion (SVN) or Git will greatly impact the teams, as these tools provide version control and collaboration.\\na) While using SVN: SVN is a primitive, file-based version control system. Users might face access or deadlock issues while trying to access particular files. SVN is a centralized system, which could be vulnerable to attacks. All intellectual property or data could be corrupted or leaked.\\nb) While using Git: Git is a distributed system, so no one has authority to grant or revoke access. The particular person in the team using Git is highly secure and needs proper authentication.\\nc) Considering the collaboration between team members, using Git will help teams and simplifies the complex process of sharing and code reviews.\",\n",
      "      \"marks\": 3,\n",
      "      \"remark\": \"The comparison of architectural differences contains several inaccuracies: SVN stores deltas, not whole files, and it does support conflict resolution and rollbacks (though Git's are more advanced). Stating that in Git 'each version can be stored in a new branch' is incorrect; versions are commits. The statement that 'no one has authority to grant or revoke access' in Git is also misleading; access control is managed at the repository hosting level (e.g., GitHub, GitLab). While the answer correctly highlights the centralized vs. distributed nature and Git's benefits for collaboration, the technical details of the architectural differences are largely flawed.\"\n",
      "    },\n",
      "    {\n",
      "      \"number\": \"2.b\",\n",
      "      \"question\": \"A critical bug was introduced in the latest commit on the main branch. How would you use Git to identify the commit that introduced the bug and revert the changes?\",\n",
      "      \"text\": \"Bug hunting and requesting change. Considering the case that a critical bug was introduced in the main branch in the latest commit. (Assuming main branch is the production branch). The first step is to identify the bug in the production and roll back to the previous commit. It is certain that the bug was included in the latest commit. Git simplifies the task, like activities such as modifying, or reverting. Git reverses the changes back to previous commits. After checking, Git continuously serves the previous versions and acts as the best model that can automatically make bug-free versions. We also need to run the tests to ensure the bug has been resolved and everything is as expected.\\n\\nNext step is damage control. These could cause huge monetary damage through the system. We need to roll back the changes made in the database if the bug and its consequences are fully certain. If we have created an issue, it will push to the main branch.\\n\\nGit makes it very easy to track changes in each commit. Git maintains a record of each commit, so that person has made changes. Git makes it easy to revert the changes.\",\n",
      "      \"marks\": 3,\n",
      "      \"remark\": \"The answer correctly identifies the need to find the bug and revert, but lacks specific Git commands or strategies for identification (e.g., `git bisect`, `git blame`) and reversion (e.g., `git revert`, `git reset` with an explanation of their differences). The claim that 'Git continuously serves the previous versions and acts as the best model that can automatically make bug-free versions' is a significant misconception; Git provides tools, but the process is manual and requires human intervention for verification and fixing. The operational considerations like database rollback are good but not directly Git-related.\"\n",
      "    },\n",
      "    {\n",
      "      \"number\": \"3.a\",\n",
      "      \"question\": \"Discuss the key components and architecture of docker, including docker engine, docker hub, docker images, containers, networks, and volumes.\",\n",
      "      \"text\": \"Key components and architecture of Docker. We can consider Docker as a tool that simplifies portability issues. While developing a project, we use many packages and finally build the final code. The code needs to run on various devices and different operating systems. It is difficult to configure the project for each device. Here Docker comes in. Using Docker, we can create a Docker container which has an entire OS (operating system). This can be easily deployed on different devices without any additional configuration.\\n\\nDocker Engine: Docker Engine is a software application that can be downloaded into our system, which provides CLI commands (command-line interface) to access Docker on your computer.\\n\\nDocker Hub: Docker Hub is a web-based platform that publishes Docker repositories which contain containers and images.\\n\\nDocker Containers: A box which can have a Docker image stored inside. They are used to run/manage Docker images.\\n\\nDocker Images: Docker images are binary packages related to Docker. They make up the whole project enclosed in it.\\n\\nNetwork and Volume: The terms 'network' and 'volume' used in Docker are actually images called Volume, which is for local or Docker Hub.\",\n",
      "      \"marks\": 4,\n",
      "      \"remark\": \"Good explanations for Docker Engine, Docker Hub, Docker Containers, and Docker Images, though describing a container as having 'an entire OS' is an oversimplification; it shares the host kernel. The explanation for 'Network and Volume' is fundamentally incorrect; these are distinct components for container communication and persistent data storage, not 'images called Volume'.\"\n",
      "    },\n",
      "    {\n",
      "      \"number\": \"3.b\",\n",
      "      \"question\": \"Your team is migrating an existing monolithic application to microservices architecture using docker containers. Outline the steps and considerations for breaking down the monolith into smaller, independently deployable containers.\",\n",
      "      \"text\": \"Migrating from monolithic application architecture to Microservice architecture.\\nMonolithic application is an application that has only a single block interacting with the backend and a database. It will have backend services (APIs) accessible directly, performing calculations and operating the database.\\nMicroservice architecture: In Microservice architecture, there are many service blocks, and each service block will perform only a simple task.\\nSo, to migrate a monolithic application into a Microservice architecture application using Docker containers, the following steps can be taken:\\n1) Writing microservices\\n2) Database migration (or 'migration on its own' - unclear)\\n3) Testing microservices\\n4) Converting microservices to Docker containers (Sos - 'Source Code' - unclear)\\n5) Managing Docker containers, running the created images.\\n6) Deploying.\\n\\n[Diagram]\\nMonolithic Application: (Layer) -> (Database)\\nMicroservices: Microservice1 -> Image1, Microservice2 -> Image2, Microservice3 -> Image3 -> Docker Container\",\n",
      "      \"marks\": 6,\n",
      "      \"remark\": \"The definitions of monolithic and microservice architectures are accurate and concise. The outlined migration steps are logical and cover essential phases, including writing services, database considerations, testing, containerization, management, and deployment. The diagram, while simple, effectively illustrates the conceptual shift. The 'Sos' and 'migration on its own' parts are a little unclear, but do not significantly detract from the overall quality.\"\n",
      "    },\n",
      "    {\n",
      "      \"number\": \"6.a\",\n",
      "      \"question\": \"Compare EC2 reserved instances, on-demand instances and spot instances in terms of pricing models, cost optimization strategies and use cases for each type.\",\n",
      "      \"text\": \"Amazon Elastic Compute (EC2) is a service provided by Amazon Web Services (AWS), which provides a virtual machine on the cloud. The AWS EC2 service offers: Reserved instances, On-Demand instances, Spot instances. It is important to know which is the most stable instance model based on the use case.\\n1. Reserved Instances: These are scalable and offer a low price compared to others. Good for expected usage.\\n2. On-Demand Instances: These are scalable based on the traffic, and prices are bound to specific packages.\\n3. Spot Instances: These are pre-tested with top performance. They are efficient for applications with continuous traffic.\",\n",
      "      \"marks\": 3,\n",
      "      \"remark\": \"The answer correctly identifies the three instance types. However, the comparison is superficial and contains inaccuracies. Reserved Instances are for committed capacity and cost savings, not primarily 'scalable'. On-Demand Instances are priced per hour/second, not 'bound to specific packages'. The description of Spot Instances ('pre-tested with top performance', 'efficient for applications with continuous traffic') is incorrect; they are for fault-tolerant workloads that can handle interruptions, leveraging unused AWS capacity at a lower cost, not for uninterrupted continuous traffic.\"\n",
      "    },\n",
      "    {\n",
      "      \"number\": \"6.b\",\n",
      "      \"question\": \"List the advantages of deploying applications in docker containers. Discuss how docker simplifies application packaging, dependency management, and deployment across different environments.\",\n",
      "      \"text\": \"Advantages of deploying applications in Docker containers:\\n1. Docker containers are easily portable. No need to install packages after setup.\\n2. Easy access\\n3. Simplify [unclear - 'security' or 'testing' likely intended]\\n4. Easy application packaging.\\n5. Strict dependency management.\\n6. It supports many operating systems.\\n7. Easy deployment across different environments (Windows/Linux/Mac).\",\n",
      "      \"marks\": 4,\n",
      "      \"remark\": \"Several correct advantages are listed, such as portability, easy packaging, and dependency management. The point about 'easy access' is vague, and 'simplify' is incomplete. A significant inaccuracy is the claim that Docker containers 'support many operating systems'; containers share the host's kernel and are thus tied to the host OS architecture (e.g., Linux containers run on a Linux kernel). While Docker *itself* runs on various OS, the containers do not run natively across different kernels without a VM layer.\"\n",
      "    },\n",
      "    {\n",
      "      \"number\": \"7.a\",\n",
      "      \"question\": \"Outline the process of creating a manual test plan for a complex web application. What key elements should be included, and how would you ensure the plan is thorough and effective?\",\n",
      "      \"text\": \"Manual test plan for a complex web application. Let us consider a complex web application, a full-stack application with role-based access. Test Plan:\\n1. Identify the user roles.\\n2. Identify the actions of each user type.\\n3. Prepare test cases and include the above access and add valid and pass cases.\\n4. Include edge cases.\\nNow let us see if we are doing manual testing. There are a total of 5 user types (User, Admin, Super Admin, Org Admin, Org Manager, Org User). Here are the actions they can perform (Create Org, Create User, Add User, Manage Org, Add User to Team, Edit, Delete).\\n\\n[Table showing permissions for actions per user type - mostly incorrect or incomplete]\\n\\nBased on the table above, we can write test cases like:\\nTest Case: Scenario: User type. Expected: (Create Org, User, Edit)\\n1. Create Org: User - T, F, P\\n2. Create Org: Admin - T\\n3. Create Org: Manager - F, T, T\\nManually operate the system and assign a different rule and validate whether the table is good or bad.\",\n",
      "      \"marks\": 3,\n",
      "      \"remark\": \"The answer identifies some basic steps for creating test cases, such as identifying roles, actions, and edge cases. However, it misses many crucial elements of a comprehensive test plan (e.g., scope, objectives, entry/exit criteria, test environment, test data management, schedule, responsibilities, risk assessment, reporting). The example test matrix and cases provided are poorly structured, unclear, and contain errors, indicating a lack of practical understanding in designing effective test scenarios.\"\n",
      "    },\n",
      "    {\n",
      "      \"number\": \"7.b\",\n",
      "      \"question\": \"How would you develop a comprehensive test plan to ensure full coverage of a new feature in your application, including edge cases and potential failure points?\",\n",
      "      \"text\": \"Comprehensive test plan for a new feature. To develop a comprehensive test plan to ensure full coverage of a new feature in an application, it is mandatory to include edge cases and potential failure points. Make sure that there are no bugs and that all tests are executed.\\nFirst, we should read the requirements for the new feature and understand its functionality. It helps to find edge cases while testing.\\nPerform Unit testing, Integration testing, Acceptance testing (or 'functional testing') with all edge cases. Also, use top-down and bottom-up approaches. Make sure that there are no bugs and understand the behavior of the feature. Make sure that the features meet requirements and that everything is okay. This is the main priority to develop a comprehensive test plan to cover full coverage of the new feature in an application.\",\n",
      "      \"marks\": 5,\n",
      "      \"remark\": \"The answer correctly emphasizes the inclusion of edge cases, potential failure points, and the importance of understanding requirements. It also appropriately mentions different levels of testing (Unit, Integration, Acceptance/Functional). The mention of 'top-down and bottom-up approaches' is relevant, although not elaborated. Similar to 7.a, it focuses more on test design principles rather than the complete structure and content of a 'comprehensive test plan' document, which typically includes scope, objectives, resources, schedule, etc.\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "82d21256",
   "metadata": {},
   "outputs": [],
   "source": [
    "filteredText = response.text.replace(\"```json\", \"\").replace(\"```\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "001de0ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"\\\\n{\\\\n  \\\\\"answers\\\\\": [\\\\n    {\\\\n      \\\\\"number\\\\\": \\\\\"1.a\\\\\",\\\\n      \\\\\"question\\\\\": \\\\\"Explain the process of branching and merging in Git. What are the best practices for managing branches and resolving conflicts?\\\\\",\\\\n      \\\\\"text\\\\\": \\\\\"Branching and Merging in Git. Git is an open-source distributed version control platform that provides various services. Git allows us to create multiple branches for the same repository. A repository is a codebase given for a project. There can be many branches for a repository which will be maintained by different teams. Suppose a company wants to add a product which is in production and the company wants to add multiple independent features for the product. Here, the company will create one new branch for each feature. Each feature is independent. For example, if a bug goes into release 0.1 for new features, here each branch is tested and built. The main (or \\'production\\') repository will have the authority to merge these branches with the production branch. And the authority is responsible for accepting the pull requests for that branch, and only then is it safe to delete the feature branch.\\\\\\\\n\\\\\\\\n[Diagram: Feature (B1), Feature (B2) -> Production Branch. begin) B3. (various arrows and text like git push, merge conflicts)]\\\\\\\\n\\\\\\\\nManaging Conflicts: Conflicts sometimes occur when you are merging branches. The best practices for managing conflicts in Git is to ensure the files are properly imported. Add all related modules correctly. To resolve conflicts, you should re-read the code. Only the bug-free branches can be merged with the production branch.\\\\\",\\\\n      \\\\\"marks\\\\\": 5,\\\\n      \\\\\"remark\\\\\": \\\\\"Good explanation of branching and merging with a clear example. The description of conflict resolution best practices is somewhat generic and lacks specific Git commands or advanced strategies like `git mergetool` or `git rebase`.\\\\\"\\\\n    },\\\\n    {\\\\n      \\\\\"number\\\\\": \\\\\"1.b\\\\\",\\\\n      \\\\\"question\\\\\": \\\\\"Your team is struggling with maintaining consistency in infrastructure configurations across multiple environments. How would you implement infrastructure as Code (IaC) to address this challenge?\\\\\",\\\\n      \\\\\"text\\\\\": \\\\\"Struggling with maintaining consistency in infrastructure configurations across multiple environments. Inconsistency in maintaining infrastructure configurations across multiple environments could lead to issues like system crashes, accessibility problems, reliability issues, performance issues, and bad user experience. Implementing Infrastructure as Code (IaC) will solve this inconsistency challenge. Our issue is to deploy on multiple environments. Infrastructure as Code will help maintain the configurations in infrastructure across multiple environments, which directly resolves problems with varying response times, multiple environment scalability issues, and performance issues. To implement Infrastructure as Code, developers should have good knowledge about how code can be modularized, reusable, and structured. They should follow SOLID principles and implement practices like caching and implicit dependencies. For example, \\'refresh on refresh\\' (this seems like a random example, perhaps meant to illustrate a concept but is poorly explained). This is a common method for many products to make the user feel like the data is loaded instantaneously. But in reality, all data will load in parts, which is pre-loaded when the application is opened, and the data is refreshed and stored when the user opens the particular page. This gives the illusion that the data is loaded instantaneously. This problem of inconsistency in infrastructure configuration across multiple environments could be solved using the Infrastructure as Code (IaC) technique.\\\\\",\\\\n      \\\\\"marks\\\\\": 4,\\\\n      \\\\\"remark\\\\\": \\\\\"Correctly identifies the problem and proposes IaC as the solution, listing relevant benefits and general principles for developers. However, the lengthy \\'refresh on refresh\\' example is completely irrelevant to IaC and infrastructure consistency, distracting from the core answer. It also doesn\\'t mention specific IaC tools (e.g., Terraform, Ansible, Chef, Puppet) which would strengthen the implementation aspect.\\\\\"\\\\n    },\\\\n    {\\\\n      \\\\\"number\\\\\": \\\\\"2.a\\\\\",\\\\n      \\\\\"question\\\\\": \\\\\"Discuss the key architectural differences between SVN and Git. How do these differences impact the way teams use these tools for version control and collaboration?\\\\\",\\\\n      \\\\\"text\\\\\": \\\\\"Subversion (SVN) and Git. Key architectural differences: Subversion (SVN) System is a file-based system. It stores each version as a whole file. Limited offline control. Lacks abilities like conflict resolution and rollbacks. Git is an open-source Version Control Software. Each version can be stored in a new branch. Unlimited offline control. Has special abilities like conflict resolution and instant rollbacks.\\\\\\\\n\\\\\\\\nImpact on Teams: Using Subversion (SVN) or Git will greatly impact the teams, as these tools provide version control and collaboration.\\\\\\\\na) While using SVN: SVN is a primitive, file-based version control system. Users might face access or deadlock issues while trying to access particular files. SVN is a centralized system, which could be vulnerable to attacks. All intellectual property or data could be corrupted or leaked.\\\\\\\\nb) While using Git: Git is a distributed system, so no one has authority to grant or revoke access. The particular person in the team using Git is highly secure and needs proper authentication.\\\\\\\\nc) Considering the collaboration between team members, using Git will help teams and simplifies the complex process of sharing and code reviews.\\\\\",\\\\n      \\\\\"marks\\\\\": 3,\\\\n      \\\\\"remark\\\\\": \\\\\"The comparison of architectural differences contains several inaccuracies: SVN stores deltas, not whole files, and it does support conflict resolution and rollbacks (though Git\\'s are more advanced). Stating that in Git \\'each version can be stored in a new branch\\' is incorrect; versions are commits. The statement that \\'no one has authority to grant or revoke access\\' in Git is also misleading; access control is managed at the repository hosting level (e.g., GitHub, GitLab). While the answer correctly highlights the centralized vs. distributed nature and Git\\'s benefits for collaboration, the technical details of the architectural differences are largely flawed.\\\\\"\\\\n    },\\\\n    {\\\\n      \\\\\"number\\\\\": \\\\\"2.b\\\\\",\\\\n      \\\\\"question\\\\\": \\\\\"A critical bug was introduced in the latest commit on the main branch. How would you use Git to identify the commit that introduced the bug and revert the changes?\\\\\",\\\\n      \\\\\"text\\\\\": \\\\\"Bug hunting and requesting change. Considering the case that a critical bug was introduced in the main branch in the latest commit. (Assuming main branch is the production branch). The first step is to identify the bug in the production and roll back to the previous commit. It is certain that the bug was included in the latest commit. Git simplifies the task, like activities such as modifying, or reverting. Git reverses the changes back to previous commits. After checking, Git continuously serves the previous versions and acts as the best model that can automatically make bug-free versions. We also need to run the tests to ensure the bug has been resolved and everything is as expected.\\\\\\\\n\\\\\\\\nNext step is damage control. These could cause huge monetary damage through the system. We need to roll back the changes made in the database if the bug and its consequences are fully certain. If we have created an issue, it will push to the main branch.\\\\\\\\n\\\\\\\\nGit makes it very easy to track changes in each commit. Git maintains a record of each commit, so that person has made changes. Git makes it easy to revert the changes.\\\\\",\\\\n      \\\\\"marks\\\\\": 3,\\\\n      \\\\\"remark\\\\\": \\\\\"The answer correctly identifies the need to find the bug and revert, but lacks specific Git commands or strategies for identification (e.g., `git bisect`, `git blame`) and reversion (e.g., `git revert`, `git reset` with an explanation of their differences). The claim that \\'Git continuously serves the previous versions and acts as the best model that can automatically make bug-free versions\\' is a significant misconception; Git provides tools, but the process is manual and requires human intervention for verification and fixing. The operational considerations like database rollback are good but not directly Git-related.\\\\\"\\\\n    },\\\\n    {\\\\n      \\\\\"number\\\\\": \\\\\"3.a\\\\\",\\\\n      \\\\\"question\\\\\": \\\\\"Discuss the key components and architecture of docker, including docker engine, docker hub, docker images, containers, networks, and volumes.\\\\\",\\\\n      \\\\\"text\\\\\": \\\\\"Key components and architecture of Docker. We can consider Docker as a tool that simplifies portability issues. While developing a project, we use many packages and finally build the final code. The code needs to run on various devices and different operating systems. It is difficult to configure the project for each device. Here Docker comes in. Using Docker, we can create a Docker container which has an entire OS (operating system). This can be easily deployed on different devices without any additional configuration.\\\\\\\\n\\\\\\\\nDocker Engine: Docker Engine is a software application that can be downloaded into our system, which provides CLI commands (command-line interface) to access Docker on your computer.\\\\\\\\n\\\\\\\\nDocker Hub: Docker Hub is a web-based platform that publishes Docker repositories which contain containers and images.\\\\\\\\n\\\\\\\\nDocker Containers: A box which can have a Docker image stored inside. They are used to run/manage Docker images.\\\\\\\\n\\\\\\\\nDocker Images: Docker images are binary packages related to Docker. They make up the whole project enclosed in it.\\\\\\\\n\\\\\\\\nNetwork and Volume: The terms \\'network\\' and \\'volume\\' used in Docker are actually images called Volume, which is for local or Docker Hub.\\\\\",\\\\n      \\\\\"marks\\\\\": 4,\\\\n      \\\\\"remark\\\\\": \\\\\"Good explanations for Docker Engine, Docker Hub, Docker Containers, and Docker Images, though describing a container as having \\'an entire OS\\' is an oversimplification; it shares the host kernel. The explanation for \\'Network and Volume\\' is fundamentally incorrect; these are distinct components for container communication and persistent data storage, not \\'images called Volume\\'.\\\\\"\\\\n    },\\\\n    {\\\\n      \\\\\"number\\\\\": \\\\\"3.b\\\\\",\\\\n      \\\\\"question\\\\\": \\\\\"Your team is migrating an existing monolithic application to microservices architecture using docker containers. Outline the steps and considerations for breaking down the monolith into smaller, independently deployable containers.\\\\\",\\\\n      \\\\\"text\\\\\": \\\\\"Migrating from monolithic application architecture to Microservice architecture.\\\\\\\\nMonolithic application is an application that has only a single block interacting with the backend and a database. It will have backend services (APIs) accessible directly, performing calculations and operating the database.\\\\\\\\nMicroservice architecture: In Microservice architecture, there are many service blocks, and each service block will perform only a simple task.\\\\\\\\nSo, to migrate a monolithic application into a Microservice architecture application using Docker containers, the following steps can be taken:\\\\\\\\n1) Writing microservices\\\\\\\\n2) Database migration (or \\'migration on its own\\' - unclear)\\\\\\\\n3) Testing microservices\\\\\\\\n4) Converting microservices to Docker containers (Sos - \\'Source Code\\' - unclear)\\\\\\\\n5) Managing Docker containers, running the created images.\\\\\\\\n6) Deploying.\\\\\\\\n\\\\\\\\n[Diagram]\\\\\\\\nMonolithic Application: (Layer) -> (Database)\\\\\\\\nMicroservices: Microservice1 -> Image1, Microservice2 -> Image2, Microservice3 -> Image3 -> Docker Container\\\\\",\\\\n      \\\\\"marks\\\\\": 6,\\\\n      \\\\\"remark\\\\\": \\\\\"The definitions of monolithic and microservice architectures are accurate and concise. The outlined migration steps are logical and cover essential phases, including writing services, database considerations, testing, containerization, management, and deployment. The diagram, while simple, effectively illustrates the conceptual shift. The \\'Sos\\' and \\'migration on its own\\' parts are a little unclear, but do not significantly detract from the overall quality.\\\\\"\\\\n    },\\\\n    {\\\\n      \\\\\"number\\\\\": \\\\\"6.a\\\\\",\\\\n      \\\\\"question\\\\\": \\\\\"Compare EC2 reserved instances, on-demand instances and spot instances in terms of pricing models, cost optimization strategies and use cases for each type.\\\\\",\\\\n      \\\\\"text\\\\\": \\\\\"Amazon Elastic Compute (EC2) is a service provided by Amazon Web Services (AWS), which provides a virtual machine on the cloud. The AWS EC2 service offers: Reserved instances, On-Demand instances, Spot instances. It is important to know which is the most stable instance model based on the use case.\\\\\\\\n1. Reserved Instances: These are scalable and offer a low price compared to others. Good for expected usage.\\\\\\\\n2. On-Demand Instances: These are scalable based on the traffic, and prices are bound to specific packages.\\\\\\\\n3. Spot Instances: These are pre-tested with top performance. They are efficient for applications with continuous traffic.\\\\\",\\\\n      \\\\\"marks\\\\\": 3,\\\\n      \\\\\"remark\\\\\": \\\\\"The answer correctly identifies the three instance types. However, the comparison is superficial and contains inaccuracies. Reserved Instances are for committed capacity and cost savings, not primarily \\'scalable\\'. On-Demand Instances are priced per hour/second, not \\'bound to specific packages\\'. The description of Spot Instances (\\'pre-tested with top performance\\', \\'efficient for applications with continuous traffic\\') is incorrect; they are for fault-tolerant workloads that can handle interruptions, leveraging unused AWS capacity at a lower cost, not for uninterrupted continuous traffic.\\\\\"\\\\n    },\\\\n    {\\\\n      \\\\\"number\\\\\": \\\\\"6.b\\\\\",\\\\n      \\\\\"question\\\\\": \\\\\"List the advantages of deploying applications in docker containers. Discuss how docker simplifies application packaging, dependency management, and deployment across different environments.\\\\\",\\\\n      \\\\\"text\\\\\": \\\\\"Advantages of deploying applications in Docker containers:\\\\\\\\n1. Docker containers are easily portable. No need to install packages after setup.\\\\\\\\n2. Easy access\\\\\\\\n3. Simplify [unclear - \\'security\\' or \\'testing\\' likely intended]\\\\\\\\n4. Easy application packaging.\\\\\\\\n5. Strict dependency management.\\\\\\\\n6. It supports many operating systems.\\\\\\\\n7. Easy deployment across different environments (Windows/Linux/Mac).\\\\\",\\\\n      \\\\\"marks\\\\\": 4,\\\\n      \\\\\"remark\\\\\": \\\\\"Several correct advantages are listed, such as portability, easy packaging, and dependency management. The point about \\'easy access\\' is vague, and \\'simplify\\' is incomplete. A significant inaccuracy is the claim that Docker containers \\'support many operating systems\\'; containers share the host\\'s kernel and are thus tied to the host OS architecture (e.g., Linux containers run on a Linux kernel). While Docker *itself* runs on various OS, the containers do not run natively across different kernels without a VM layer.\\\\\"\\\\n    },\\\\n    {\\\\n      \\\\\"number\\\\\": \\\\\"7.a\\\\\",\\\\n      \\\\\"question\\\\\": \\\\\"Outline the process of creating a manual test plan for a complex web application. What key elements should be included, and how would you ensure the plan is thorough and effective?\\\\\",\\\\n      \\\\\"text\\\\\": \\\\\"Manual test plan for a complex web application. Let us consider a complex web application, a full-stack application with role-based access. Test Plan:\\\\\\\\n1. Identify the user roles.\\\\\\\\n2. Identify the actions of each user type.\\\\\\\\n3. Prepare test cases and include the above access and add valid and pass cases.\\\\\\\\n4. Include edge cases.\\\\\\\\nNow let us see if we are doing manual testing. There are a total of 5 user types (User, Admin, Super Admin, Org Admin, Org Manager, Org User). Here are the actions they can perform (Create Org, Create User, Add User, Manage Org, Add User to Team, Edit, Delete).\\\\\\\\n\\\\\\\\n[Table showing permissions for actions per user type - mostly incorrect or incomplete]\\\\\\\\n\\\\\\\\nBased on the table above, we can write test cases like:\\\\\\\\nTest Case: Scenario: User type. Expected: (Create Org, User, Edit)\\\\\\\\n1. Create Org: User - T, F, P\\\\\\\\n2. Create Org: Admin - T\\\\\\\\n3. Create Org: Manager - F, T, T\\\\\\\\nManually operate the system and assign a different rule and validate whether the table is good or bad.\\\\\",\\\\n      \\\\\"marks\\\\\": 3,\\\\n      \\\\\"remark\\\\\": \\\\\"The answer identifies some basic steps for creating test cases, such as identifying roles, actions, and edge cases. However, it misses many crucial elements of a comprehensive test plan (e.g., scope, objectives, entry/exit criteria, test environment, test data management, schedule, responsibilities, risk assessment, reporting). The example test matrix and cases provided are poorly structured, unclear, and contain errors, indicating a lack of practical understanding in designing effective test scenarios.\\\\\"\\\\n    },\\\\n    {\\\\n      \\\\\"number\\\\\": \\\\\"7.b\\\\\",\\\\n      \\\\\"question\\\\\": \\\\\"How would you develop a comprehensive test plan to ensure full coverage of a new feature in your application, including edge cases and potential failure points?\\\\\",\\\\n      \\\\\"text\\\\\": \\\\\"Comprehensive test plan for a new feature. To develop a comprehensive test plan to ensure full coverage of a new feature in an application, it is mandatory to include edge cases and potential failure points. Make sure that there are no bugs and that all tests are executed.\\\\\\\\nFirst, we should read the requirements for the new feature and understand its functionality. It helps to find edge cases while testing.\\\\\\\\nPerform Unit testing, Integration testing, Acceptance testing (or \\'functional testing\\') with all edge cases. Also, use top-down and bottom-up approaches. Make sure that there are no bugs and understand the behavior of the feature. Make sure that the features meet requirements and that everything is okay. This is the main priority to develop a comprehensive test plan to cover full coverage of the new feature in an application.\\\\\",\\\\n      \\\\\"marks\\\\\": 5,\\\\n      \\\\\"remark\\\\\": \\\\\"The answer correctly emphasizes the inclusion of edge cases, potential failure points, and the importance of understanding requirements. It also appropriately mentions different levels of testing (Unit, Integration, Acceptance/Functional). The mention of \\'top-down and bottom-up approaches\\' is relevant, although not elaborated. Similar to 7.a, it focuses more on test design principles rather than the complete structure and content of a \\'comprehensive test plan\\' document, which typically includes scope, objectives, resources, schedule, etc.\\\\\"\\\\n    }\\\\n  ]\\\\n}\\\\n\"'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.dumps(filteredText, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "afe09ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"answers\": [\n",
      "    {\n",
      "      \"number\": \"1.a\",\n",
      "      \"question\": \"Explain the process of branching and merging in Git. What are the best practices for managing branches and resolving conflicts?\",\n",
      "      \"text\": \"Branching and Merging in Git. Git is an open-source distributed version control platform that provides various services. Git allows us to create multiple branches for the same repository. A repository is a codebase given for a project. There can be many branches for a repository which will be maintained by different teams. Suppose a company wants to add a product which is in production and the company wants to add multiple independent features for the product. Here, the company will create one new branch for each feature. Each feature is independent. For example, if a bug goes into release 0.1 for new features, here each branch is tested and built. The main (or 'production') repository will have the authority to merge these branches with the production branch. And the authority is responsible for accepting the pull requests for that branch, and only then is it safe to delete the feature branch.\\n\\n[Diagram: Feature (B1), Feature (B2) -> Production Branch. begin) B3. (various arrows and text like git push, merge conflicts)]\\n\\nManaging Conflicts: Conflicts sometimes occur when you are merging branches. The best practices for managing conflicts in Git is to ensure the files are properly imported. Add all related modules correctly. To resolve conflicts, you should re-read the code. Only the bug-free branches can be merged with the production branch.\",\n",
      "      \"marks\": 5,\n",
      "      \"remark\": \"Good explanation of branching and merging with a clear example. The description of conflict resolution best practices is somewhat generic and lacks specific Git commands or advanced strategies like `git mergetool` or `git rebase`.\"\n",
      "    },\n",
      "    {\n",
      "      \"number\": \"1.b\",\n",
      "      \"question\": \"Your team is struggling with maintaining consistency in infrastructure configurations across multiple environments. How would you implement infrastructure as Code (IaC) to address this challenge?\",\n",
      "      \"text\": \"Struggling with maintaining consistency in infrastructure configurations across multiple environments. Inconsistency in maintaining infrastructure configurations across multiple environments could lead to issues like system crashes, accessibility problems, reliability issues, performance issues, and bad user experience. Implementing Infrastructure as Code (IaC) will solve this inconsistency challenge. Our issue is to deploy on multiple environments. Infrastructure as Code will help maintain the configurations in infrastructure across multiple environments, which directly resolves problems with varying response times, multiple environment scalability issues, and performance issues. To implement Infrastructure as Code, developers should have good knowledge about how code can be modularized, reusable, and structured. They should follow SOLID principles and implement practices like caching and implicit dependencies. For example, 'refresh on refresh' (this seems like a random example, perhaps meant to illustrate a concept but is poorly explained). This is a common method for many products to make the user feel like the data is loaded instantaneously. But in reality, all data will load in parts, which is pre-loaded when the application is opened, and the data is refreshed and stored when the user opens the particular page. This gives the illusion that the data is loaded instantaneously. This problem of inconsistency in infrastructure configuration across multiple environments could be solved using the Infrastructure as Code (IaC) technique.\",\n",
      "      \"marks\": 4,\n",
      "      \"remark\": \"Correctly identifies the problem and proposes IaC as the solution, listing relevant benefits and general principles for developers. However, the lengthy 'refresh on refresh' example is completely irrelevant to IaC and infrastructure consistency, distracting from the core answer. It also doesn't mention specific IaC tools (e.g., Terraform, Ansible, Chef, Puppet) which would strengthen the implementation aspect.\"\n",
      "    },\n",
      "    {\n",
      "      \"number\": \"2.a\",\n",
      "      \"question\": \"Discuss the key architectural differences between SVN and Git. How do these differences impact the way teams use these tools for version control and collaboration?\",\n",
      "      \"text\": \"Subversion (SVN) and Git. Key architectural differences: Subversion (SVN) System is a file-based system. It stores each version as a whole file. Limited offline control. Lacks abilities like conflict resolution and rollbacks. Git is an open-source Version Control Software. Each version can be stored in a new branch. Unlimited offline control. Has special abilities like conflict resolution and instant rollbacks.\\n\\nImpact on Teams: Using Subversion (SVN) or Git will greatly impact the teams, as these tools provide version control and collaboration.\\na) While using SVN: SVN is a primitive, file-based version control system. Users might face access or deadlock issues while trying to access particular files. SVN is a centralized system, which could be vulnerable to attacks. All intellectual property or data could be corrupted or leaked.\\nb) While using Git: Git is a distributed system, so no one has authority to grant or revoke access. The particular person in the team using Git is highly secure and needs proper authentication.\\nc) Considering the collaboration between team members, using Git will help teams and simplifies the complex process of sharing and code reviews.\",\n",
      "      \"marks\": 3,\n",
      "      \"remark\": \"The comparison of architectural differences contains several inaccuracies: SVN stores deltas, not whole files, and it does support conflict resolution and rollbacks (though Git's are more advanced). Stating that in Git 'each version can be stored in a new branch' is incorrect; versions are commits. The statement that 'no one has authority to grant or revoke access' in Git is also misleading; access control is managed at the repository hosting level (e.g., GitHub, GitLab). While the answer correctly highlights the centralized vs. distributed nature and Git's benefits for collaboration, the technical details of the architectural differences are largely flawed.\"\n",
      "    },\n",
      "    {\n",
      "      \"number\": \"2.b\",\n",
      "      \"question\": \"A critical bug was introduced in the latest commit on the main branch. How would you use Git to identify the commit that introduced the bug and revert the changes?\",\n",
      "      \"text\": \"Bug hunting and requesting change. Considering the case that a critical bug was introduced in the main branch in the latest commit. (Assuming main branch is the production branch). The first step is to identify the bug in the production and roll back to the previous commit. It is certain that the bug was included in the latest commit. Git simplifies the task, like activities such as modifying, or reverting. Git reverses the changes back to previous commits. After checking, Git continuously serves the previous versions and acts as the best model that can automatically make bug-free versions. We also need to run the tests to ensure the bug has been resolved and everything is as expected.\\n\\nNext step is damage control. These could cause huge monetary damage through the system. We need to roll back the changes made in the database if the bug and its consequences are fully certain. If we have created an issue, it will push to the main branch.\\n\\nGit makes it very easy to track changes in each commit. Git maintains a record of each commit, so that person has made changes. Git makes it easy to revert the changes.\",\n",
      "      \"marks\": 3,\n",
      "      \"remark\": \"The answer correctly identifies the need to find the bug and revert, but lacks specific Git commands or strategies for identification (e.g., `git bisect`, `git blame`) and reversion (e.g., `git revert`, `git reset` with an explanation of their differences). The claim that 'Git continuously serves the previous versions and acts as the best model that can automatically make bug-free versions' is a significant misconception; Git provides tools, but the process is manual and requires human intervention for verification and fixing. The operational considerations like database rollback are good but not directly Git-related.\"\n",
      "    },\n",
      "    {\n",
      "      \"number\": \"3.a\",\n",
      "      \"question\": \"Discuss the key components and architecture of docker, including docker engine, docker hub, docker images, containers, networks, and volumes.\",\n",
      "      \"text\": \"Key components and architecture of Docker. We can consider Docker as a tool that simplifies portability issues. While developing a project, we use many packages and finally build the final code. The code needs to run on various devices and different operating systems. It is difficult to configure the project for each device. Here Docker comes in. Using Docker, we can create a Docker container which has an entire OS (operating system). This can be easily deployed on different devices without any additional configuration.\\n\\nDocker Engine: Docker Engine is a software application that can be downloaded into our system, which provides CLI commands (command-line interface) to access Docker on your computer.\\n\\nDocker Hub: Docker Hub is a web-based platform that publishes Docker repositories which contain containers and images.\\n\\nDocker Containers: A box which can have a Docker image stored inside. They are used to run/manage Docker images.\\n\\nDocker Images: Docker images are binary packages related to Docker. They make up the whole project enclosed in it.\\n\\nNetwork and Volume: The terms 'network' and 'volume' used in Docker are actually images called Volume, which is for local or Docker Hub.\",\n",
      "      \"marks\": 4,\n",
      "      \"remark\": \"Good explanations for Docker Engine, Docker Hub, Docker Containers, and Docker Images, though describing a container as having 'an entire OS' is an oversimplification; it shares the host kernel. The explanation for 'Network and Volume' is fundamentally incorrect; these are distinct components for container communication and persistent data storage, not 'images called Volume'.\"\n",
      "    },\n",
      "    {\n",
      "      \"number\": \"3.b\",\n",
      "      \"question\": \"Your team is migrating an existing monolithic application to microservices architecture using docker containers. Outline the steps and considerations for breaking down the monolith into smaller, independently deployable containers.\",\n",
      "      \"text\": \"Migrating from monolithic application architecture to Microservice architecture.\\nMonolithic application is an application that has only a single block interacting with the backend and a database. It will have backend services (APIs) accessible directly, performing calculations and operating the database.\\nMicroservice architecture: In Microservice architecture, there are many service blocks, and each service block will perform only a simple task.\\nSo, to migrate a monolithic application into a Microservice architecture application using Docker containers, the following steps can be taken:\\n1) Writing microservices\\n2) Database migration (or 'migration on its own' - unclear)\\n3) Testing microservices\\n4) Converting microservices to Docker containers (Sos - 'Source Code' - unclear)\\n5) Managing Docker containers, running the created images.\\n6) Deploying.\\n\\n[Diagram]\\nMonolithic Application: (Layer) -> (Database)\\nMicroservices: Microservice1 -> Image1, Microservice2 -> Image2, Microservice3 -> Image3 -> Docker Container\",\n",
      "      \"marks\": 6,\n",
      "      \"remark\": \"The definitions of monolithic and microservice architectures are accurate and concise. The outlined migration steps are logical and cover essential phases, including writing services, database considerations, testing, containerization, management, and deployment. The diagram, while simple, effectively illustrates the conceptual shift. The 'Sos' and 'migration on its own' parts are a little unclear, but do not significantly detract from the overall quality.\"\n",
      "    },\n",
      "    {\n",
      "      \"number\": \"6.a\",\n",
      "      \"question\": \"Compare EC2 reserved instances, on-demand instances and spot instances in terms of pricing models, cost optimization strategies and use cases for each type.\",\n",
      "      \"text\": \"Amazon Elastic Compute (EC2) is a service provided by Amazon Web Services (AWS), which provides a virtual machine on the cloud. The AWS EC2 service offers: Reserved instances, On-Demand instances, Spot instances. It is important to know which is the most stable instance model based on the use case.\\n1. Reserved Instances: These are scalable and offer a low price compared to others. Good for expected usage.\\n2. On-Demand Instances: These are scalable based on the traffic, and prices are bound to specific packages.\\n3. Spot Instances: These are pre-tested with top performance. They are efficient for applications with continuous traffic.\",\n",
      "      \"marks\": 3,\n",
      "      \"remark\": \"The answer correctly identifies the three instance types. However, the comparison is superficial and contains inaccuracies. Reserved Instances are for committed capacity and cost savings, not primarily 'scalable'. On-Demand Instances are priced per hour/second, not 'bound to specific packages'. The description of Spot Instances ('pre-tested with top performance', 'efficient for applications with continuous traffic') is incorrect; they are for fault-tolerant workloads that can handle interruptions, leveraging unused AWS capacity at a lower cost, not for uninterrupted continuous traffic.\"\n",
      "    },\n",
      "    {\n",
      "      \"number\": \"6.b\",\n",
      "      \"question\": \"List the advantages of deploying applications in docker containers. Discuss how docker simplifies application packaging, dependency management, and deployment across different environments.\",\n",
      "      \"text\": \"Advantages of deploying applications in Docker containers:\\n1. Docker containers are easily portable. No need to install packages after setup.\\n2. Easy access\\n3. Simplify [unclear - 'security' or 'testing' likely intended]\\n4. Easy application packaging.\\n5. Strict dependency management.\\n6. It supports many operating systems.\\n7. Easy deployment across different environments (Windows/Linux/Mac).\",\n",
      "      \"marks\": 4,\n",
      "      \"remark\": \"Several correct advantages are listed, such as portability, easy packaging, and dependency management. The point about 'easy access' is vague, and 'simplify' is incomplete. A significant inaccuracy is the claim that Docker containers 'support many operating systems'; containers share the host's kernel and are thus tied to the host OS architecture (e.g., Linux containers run on a Linux kernel). While Docker *itself* runs on various OS, the containers do not run natively across different kernels without a VM layer.\"\n",
      "    },\n",
      "    {\n",
      "      \"number\": \"7.a\",\n",
      "      \"question\": \"Outline the process of creating a manual test plan for a complex web application. What key elements should be included, and how would you ensure the plan is thorough and effective?\",\n",
      "      \"text\": \"Manual test plan for a complex web application. Let us consider a complex web application, a full-stack application with role-based access. Test Plan:\\n1. Identify the user roles.\\n2. Identify the actions of each user type.\\n3. Prepare test cases and include the above access and add valid and pass cases.\\n4. Include edge cases.\\nNow let us see if we are doing manual testing. There are a total of 5 user types (User, Admin, Super Admin, Org Admin, Org Manager, Org User). Here are the actions they can perform (Create Org, Create User, Add User, Manage Org, Add User to Team, Edit, Delete).\\n\\n[Table showing permissions for actions per user type - mostly incorrect or incomplete]\\n\\nBased on the table above, we can write test cases like:\\nTest Case: Scenario: User type. Expected: (Create Org, User, Edit)\\n1. Create Org: User - T, F, P\\n2. Create Org: Admin - T\\n3. Create Org: Manager - F, T, T\\nManually operate the system and assign a different rule and validate whether the table is good or bad.\",\n",
      "      \"marks\": 3,\n",
      "      \"remark\": \"The answer identifies some basic steps for creating test cases, such as identifying roles, actions, and edge cases. However, it misses many crucial elements of a comprehensive test plan (e.g., scope, objectives, entry/exit criteria, test environment, test data management, schedule, responsibilities, risk assessment, reporting). The example test matrix and cases provided are poorly structured, unclear, and contain errors, indicating a lack of practical understanding in designing effective test scenarios.\"\n",
      "    },\n",
      "    {\n",
      "      \"number\": \"7.b\",\n",
      "      \"question\": \"How would you develop a comprehensive test plan to ensure full coverage of a new feature in your application, including edge cases and potential failure points?\",\n",
      "      \"text\": \"Comprehensive test plan for a new feature. To develop a comprehensive test plan to ensure full coverage of a new feature in an application, it is mandatory to include edge cases and potential failure points. Make sure that there are no bugs and that all tests are executed.\\nFirst, we should read the requirements for the new feature and understand its functionality. It helps to find edge cases while testing.\\nPerform Unit testing, Integration testing, Acceptance testing (or 'functional testing') with all edge cases. Also, use top-down and bottom-up approaches. Make sure that there are no bugs and understand the behavior of the feature. Make sure that the features meet requirements and that everything is okay. This is the main priority to develop a comprehensive test plan to cover full coverage of the new feature in an application.\",\n",
      "      \"marks\": 5,\n",
      "      \"remark\": \"The answer correctly emphasizes the inclusion of edge cases, potential failure points, and the importance of understanding requirements. It also appropriately mentions different levels of testing (Unit, Integration, Acceptance/Functional). The mention of 'top-down and bottom-up approaches' is relevant, although not elaborated. Similar to 7.a, it focuses more on test design principles rather than the complete structure and content of a 'comprehensive test plan' document, which typically includes scope, objectives, resources, schedule, etc.\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "✅ JSON saved to g8/devops-result.json\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(f\"results/{roll}\", exist_ok=True)  # This creates the folder if it doesn't exist\n",
    "\n",
    "try:\n",
    "    data = json.loads(filteredText)\n",
    "\n",
    "    # Pretty print\n",
    "    print(json.dumps(data, indent=2))\n",
    "\n",
    "    # Save to file\n",
    "    with open(f\"results/{roll}/{sub}-result.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    print(f\"✅ JSON saved to {roll}/{sub}-result.json\")\n",
    "\n",
    "except json.JSONDecodeError as e:\n",
    "    print(\"⚠️ Model output wasn't pure JSON, but you can regex/cleanup.\")\n",
    "    print(\"Error:\", e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "evaluate.ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
